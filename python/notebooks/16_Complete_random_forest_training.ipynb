{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "limited-evidence",
   "metadata": {},
   "source": [
    "# Completely Random Forest training with encrypted data using FHE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-highland",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This example shows how to train a completely-random-forest (CRF) [1] with encryption of UCI-adult dataset [2-3] using FHE.\n",
    "Our CRF implementation supports features of binary-value type.\n",
    "Therefore features of categorical (non-ordinal) type need to be preprocessed as one-hot vectors (see explanation in [1] section 2.2). Features that contain numeric values are first splitted to a fix number of sub-range buckets, then each value is mapped to one-hot ordinal representation according to the buckets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463e3042",
   "metadata": {},
   "source": [
    "This demo uses SEAL backend since release 1.5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-minutes",
   "metadata": {},
   "source": [
    "Reading the UCI-adult dataset from file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-dakota",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from utils import elapsed_timer, get_used_ram, get_data_sets_dir\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "INPUT_DIR = os.path.join(get_data_sets_dir(), 'uci_adult')\n",
    "train_data = pd.read_csv(os.path.join(INPUT_DIR, \"adult.data\"), header=None)\n",
    "X_train = train_data.iloc[:,:-1]\n",
    "y_train = train_data.iloc[:,-1]\n",
    "\n",
    "test_data = pd.read_csv(os.path.join(INPUT_DIR, \"adult.test\"), header=None, skiprows=1, sep=\"[,.]\")\n",
    "X_test = test_data.iloc[:,:-2]\n",
    "y_test = test_data.iloc[:,-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-survivor",
   "metadata": {},
   "source": [
    "Initialize HElayers context for 128 bit security level such that each ciphertext pack 4096 plaintext values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhelayers\n",
    "# Request a SEAL context\n",
    "he_context = pyhelayers.HeContext.create([\"SEAL_CKKS\"])\n",
    "requirements = pyhelayers.HeConfigRequirement(\n",
    "    num_slots = 4096,\n",
    "    multiplication_depth = 3,\n",
    "    fractional_part_precision = 36,\n",
    "    integer_part_precision = 17,\n",
    "    security_level = 128)\n",
    "\n",
    "he_context.init(requirements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-honduras",
   "metadata": {},
   "source": [
    "Preprocessing all features to binary features.  We read the data in batches of a size equal to the number of slots. For best performance, we recommend on choosing batch size equals to an integer multiplication of the number of ciphertext's slots i.e., he_context.slot_count().\n",
    "For ordinal features, the number of bins determines the granularity of it's binary representation - see [1] section 2.2 for further discussion on data representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc.crf_utils import Preprocessor\n",
    "batch_size = he_context.slot_count()\n",
    "prep = Preprocessor(num_bins = 10, batch_size = batch_size)\n",
    "cat_predictors, ord_predictors  = prep.preprocess_predictor_descriptions(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-welding",
   "metadata": {},
   "source": [
    "Set CRF model hyperparameters: the number of trees, the tree's depth and the features types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = pyhelayers.Crf(he_context)\n",
    "crf.set_hyper_params(num_trees = 100, depth=3, categorical_predictors = cat_predictors, ordinal_predictors = ord_predictors, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-services",
   "metadata": {},
   "source": [
    "Transform the training data into batches of binary data, encrypt each batch and use it to homomorphically train the CRF. Note that in a more realistic use case, a data owner encrypts the dataset and send it to a remote server that would train the CRF with the encrypted data. However, for simplicity, we only show here a single computation entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ind = 0\n",
    "last_batch = False\n",
    "num_batches = math.ceil(len(y_train) / batch_size)\n",
    "with elapsed_timer(\"fit\", len(y_train)):\n",
    "    while not last_batch:\n",
    "        batch_ind = batch_ind + 1\n",
    "        print('fitting batch %d/%d' % (batch_ind, num_batches))\n",
    "        X_batch_oh, y_batch_oh, last_batch = prep.transform_next_batch(X_train, y_train)\n",
    "        x_train_enc, y_train_enc = crf.encode_encrypt_input(X_batch_oh, y_batch_oh)\n",
    "        crf.fit(x_train_enc, y_train_enc)\n",
    "print(\"RAM usage:\", get_used_ram(), \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095eaaa2",
   "metadata": {},
   "source": [
    "Delete `X_train` and `y_train` to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b794df22",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train\n",
    "del y_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-september",
   "metadata": {},
   "source": [
    "Decrypt the CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_plaintext = crf.decrypt_decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-implement",
   "metadata": {},
   "source": [
    "Transform the test data into batches of binary data, run inference over each batch by the plaintext CRF model and evaluate the model's AUC over all the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "last_batch = False\n",
    "y_test_bin_all = np.empty([0,1])\n",
    "y_pred_proba_all = np.empty([0,2])\n",
    "batch_ind = 0\n",
    "last_batch = False\n",
    "while not last_batch:\n",
    "    batch_ind = batch_ind + 1\n",
    "    X_test_one_hot, y_test_bin, last_batch = prep.transform_next_batch(X_test, y_test)\n",
    "    y_pred_proba = crf_plaintext.predict_proba(X_test_one_hot)\n",
    "    y_test_bin_all = np.concatenate((y_test_bin_all, y_test_bin))\n",
    "    y_pred_proba_all = np.concatenate((y_pred_proba_all, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c63ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(y_test_bin_all,y_pred_proba_all[:,1])\n",
    "print(f\"AUC metrics: {auc:.2f}\")\n",
    "print(\"RAM usage:\", get_used_ram(), \"MB\")\n",
    "if (auc < 0.8):\n",
    "    raise Exception(\"AUC too small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-congo",
   "metadata": {},
   "source": [
    "Display the first tree of the trained CRF. For each leaf count of negative and positive classes are shown followed by list of conditions on the binary features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(crf_plaintext).split(\"\\ntree\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-envelope",
   "metadata": {},
   "source": [
    "## Citations\n",
    "[1] Aslett, Louis JM, Pedro M. EsperanÃ§a, and Chris C. Holmes. \"Encrypted statistical machine learning: new privacy preserving methods.\" arXiv preprint arXiv:1508.06845 (2015).\n",
    "\n",
    "[2] Kohavi,  R.,  Becker,  B.:   Uci  machine  learning  repository  -  adult  dataset  (1996), https://archive.ics.uci.edu/ml/datasets/adult18\n",
    "\n",
    "[3] Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9813121cc17402ad6eb1ec49c95df5633be2b69c8d919c50e00ffdeab1c3ee59"
  },
  "kernelspec": {
   "display_name": "fhe-py38-env",
   "language": "python",
   "name": "fhe-py38-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
