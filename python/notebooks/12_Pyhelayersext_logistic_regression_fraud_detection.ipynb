{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Inference for Fraud Detection Using FHE (simple)\n",
    "\n",
    "Expected RAM usage: less than 1 GB.  \n",
    "Expected runtime: less than 1 minute.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook is very similar to the previous Logistic Regression Fraud Detection example in Notebook 03, but uses a single line of FHE code and is much more simple. Unlike Notebook 03, you do not have to call the Optimizer, specify different parameters or encode and encrypt; you only call a single FHE command using the pyhelayers extension API. \n",
    "\n",
    "This example demonstrates the *pyhelayersext API*, which offers an easy integration with the scikit-learn library and replaces the scikit-learn predictions with the FHE implementation. The FHE configuration details are taken from fhe.json configuration file. This config file contains FHE parameters that the user can tune (e.g. batch size, security level, etc.).\n",
    "\n",
    "This demo uses the Credit Card Fraud Detection dataset, originally taken from: https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "This dataset contains actual anonymized transactions made by credit card holders from September 2013 and is labeled for transactions being fraudulent or genuine. See references at the bottom of the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Train a Logistic Regression model using standard practices\n",
    "\n",
    "In this step we'll train a Logistic Regression model using a standard ML package: sklearn\n",
    "### 1.1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import utils \n",
    "\n",
    "utils.verify_memory()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "##### For reproducibility\n",
    "seed_value= 1\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "#####\n",
    "import h5py\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import sklearn_json as skljson\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#####\n",
    "# import utils\n",
    "import sys\n",
    "path_to_utils='.'\n",
    "sys.path.append(path_to_utils)\n",
    "import utils\n",
    "\n",
    "# Disable tensorflow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "PATH = os.path.join(utils.get_data_sets_dir(), 'lr_fraud')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Read the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(utils.get_data_sets_dir(path_to_utils), 'net_fraud', 'creditcard.csv'))\n",
    "\n",
    "print(f'Reading {df.shape[0]} samples')\n",
    "\n",
    "X = df.loc[:, df.columns.tolist()[1:30]].values\n",
    "Y = df.loc[:, 'Class'].values\n",
    "print(f'number of features: {X.shape[1]}')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, stratify=Y, random_state=0)\n",
    "\n",
    "y_train = y_train.reshape(y_train.shape[0], -1)\n",
    "y_test = y_test.reshape(y_test.shape[0], -1)\n",
    "\n",
    "print(\"Training data ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Train the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=0.1)\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "print('LR model ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Test the trained model\n",
    "\n",
    "In this step we'll test the model we have trained.\n",
    "\n",
    "We are still using the standard sklearn package and performance metrics. However, we are using an import statement that will cause the usual predict method to run under encryption.\n",
    "\n",
    "This allows a data scientist to easily test the performance of AI models under encryption.\n",
    "\n",
    "### 2.1. Create a batch of 8192 test samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8192\n",
    "batch_x_test = x_test[0:batch_size,:]\n",
    "batch_y_test = y_test[0:batch_size,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix - TEST\n",
    "After the replacement below instead of regular scikit-learn code runs code predicting on encrypted data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Run prediction under encryption\n",
    "The first line below is the only line of code that deals with FHE!  \n",
    "\n",
    "It adds the pyhelayers extension, replacing the usual predict method with a predict that runs under encryption. You'll notice it's somewhat slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace predict with FHE version\n",
    "lr.predict = __import__('pyhelayers.ext').ext.replace(lr.predict, config_file='./fhe.json')\n",
    "\n",
    "batch_y_pred = lr.predict(batch_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Assess the results\n",
    "\n",
    "We now assess the results we got. The expected confusion matrix should be similar to  \n",
    "[[8175 1]  \n",
    " [6 &emsp; 10]].  \n",
    "\n",
    "Obtaining this result means the predict above running under FHE worked the same as ordinary predict in the plain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,t,thresholds = metrics.roc_curve(batch_y_test, batch_y_pred)\n",
    "cm = metrics.confusion_matrix(batch_y_test, batch_y_pred)\n",
    "print(f\"AUC Score: {metrics.auc(f,t):.3f}\")\n",
    "print(\"Classification report:\")\n",
    "print(metrics.classification_report(batch_y_test, batch_y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Test we didn't get more than 10 misclassified samples\n",
    "if (cm[1][0]+cm[0][1]>10):\n",
    "    raise Exception(\"Failed to obtain the expected confusion matrix\")\n",
    "print('Prediction under FHE succeeded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "References:\n",
    "\n",
    "<sub><sup> 1.\tAndrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015 </sup></sub>\n",
    "\n",
    "<sub><sup> 2.\tDal Pozzolo, Andrea; Caelen, Olivier; Le Borgne, Yann-Ael; Waterschoot, Serge; Bontempi, Gianluca. Learned lessons in credit card fraud detection from a practitioner perspective, Expert systems with applications,41,10,4915-4928,2014, Pergamon </sup></sub>\n",
    "\n",
    "<sub><sup> 3.\tDal Pozzolo, Andrea; Boracchi, Giacomo; Caelen, Olivier; Alippi, Cesare; Bontempi, Gianluca. Credit card fraud detection: a realistic modeling and a novel learning strategy, IEEE transactions on neural networks and learning systems,29,8,3784-3797,2018,IEEE </sup></sub>\n",
    "\n",
    "<sub><sup> 4.\tDal Pozzolo, Andrea Adaptive Machine learning for credit card fraud detection ULB MLG PhD thesis (supervised by G. Bontempi) </sup></sub>\n",
    "\n",
    "<sub><sup> 5.\tCarcillo, Fabrizio; Dal Pozzolo, Andrea; Le Borgne, Yann-Aël; Caelen, Olivier; Mazzer, Yannis; Bontempi, Gianluca. Scarff: a scalable framework for streaming credit card fraud detection with Spark, Information fusion,41, 182-194,2018,Elsevier </sup></sub>\n",
    "\n",
    "<sub><sup> 6.\tCarcillo, Fabrizio; Le Borgne, Yann-Aël; Caelen, Olivier; Bontempi, Gianluca. Streaming active learning strategies for real-life credit card fraud detection: assessment and visualization, International Journal of Data Science and Analytics, 5,4,285-300,2018,Springer International Publishing </sup></sub>\n",
    "\n",
    "<sub><sup> 7.\tBertrand Lebichot, Yann-Aël Le Borgne, Liyun He, Frederic Oblé, Gianluca Bontempi Deep-Learning Domain Adaptation Techniques for Credit Cards Fraud Detection, INNSBDDL 2019: Recent Advances in Big Data and Deep Learning, pp 78-88, 2019 </sup></sub>\n",
    "\n",
    "<sub><sup> 8.\tFabrizio Carcillo, Yann-Aël Le Borgne, Olivier Caelen, Frederic Oblé, Gianluca Bontempi Combining Unsupervised and Supervised Learning in Credit Card Fraud Detection Information Sciences, 2019 </sup></sub>\n",
    "\n",
    "<sub><sup> 9.\tYann-Aël Le Borgne, Gianluca Bontempi Machine Learning for Credit Card Fraud Detection - Practical Handbook </sup></sub>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
