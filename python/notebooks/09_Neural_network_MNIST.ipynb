{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71cefe17",
   "metadata": {},
   "source": [
    "## Inference under FHE for the MNIST Dataset using helayers\n",
    "\n",
    "In this demo, we'll deal with a classification problem for the MNIST dataset [1], trying to correctly classify a batch of samples using a neural network model that will be created and trained using the Keras library (with architecture similar to reference [2]).\n",
    "First, we'll build a plain neural network for the MNIST model. Then, we'll encrypt the trained network and run inference over it using FHE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf88e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "##### For reproducibility\n",
    "seed_value= 1\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras import utils, losses\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import h5py\n",
    "\n",
    "# import activations\n",
    "import sys\n",
    "sys.path.append(os.path.join('.', 'data_gen'))\n",
    "from activations import SquareActivation\n",
    "\n",
    "PATH = os.path.join('data', 'net_mnist')\n",
    "if not os.path.exists(PATH):\n",
    "    os.makedirs(PATH)\n",
    "\n",
    "batch_size = 500\n",
    "epochs = 10\n",
    "print(\"Misc. initializations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5bb3b0",
   "metadata": {},
   "source": [
    "### Load and Preprocess the MNIST Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c243f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('data ready')\n",
    "\n",
    "# Image padding\n",
    "x_train = np.pad(x_train, ((0, 0), (0, 1), (0, 1), (0, 0)))\n",
    "x_test = np.pad(x_test, ((0, 0), (0, 1), (0, 1), (0, 0)))\n",
    "print('Added padding. New shape: ',x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c161e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation data\n",
    "testSize=16\n",
    "x_val = x_test[:-testSize]\n",
    "x_test = x_test[-testSize:]\n",
    "y_val = y_test[:-testSize]\n",
    "y_test = y_test[-testSize:]\n",
    "print('Validation and test data ready')\n",
    "\n",
    "# Convert class vector to binary class matrices\n",
    "num_classes = 10\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)\n",
    "y_val = utils.to_categorical(y_val, num_classes)\n",
    "\n",
    "input_shape = x_train[0].shape\n",
    "print(f'input shape: {input_shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5284f27b",
   "metadata": {},
   "source": [
    "### Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969954aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_set(x, y, data_type, s=''):\n",
    "    fname=os.path.join(PATH, f'x_{data_type}{s}.h5')\n",
    "    print(\"Saving x_{} of shape {} in {}\".format(data_type, x.shape,fname))\n",
    "    xf = h5py.File(fname, 'w')\n",
    "    xf.create_dataset('x_{}'.format(data_type), data=x)\n",
    "    xf.close()\n",
    "\n",
    "    yf = h5py.File(os.path.join(PATH, f'y_{data_type}{s}.h5'), 'w')\n",
    "    yf.create_dataset(f'y_{data_type}', data=y)\n",
    "    yf.close()\n",
    "\n",
    "save_data_set(x_test, y_test, data_type='test')\n",
    "save_data_set(x_train, y_train, data_type='train')\n",
    "save_data_set(x_val, y_val, data_type='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8a6ed1",
   "metadata": {},
   "source": [
    "### Build a Plain Neural Network for the MNIST Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27228c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=5, kernel_size=5, strides=2, padding='valid',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Flatten())\n",
    "model.add(SquareActivation())\n",
    "model.add(Dense(100))\n",
    "model.add(SquareActivation())\n",
    "model.add(Dense(num_classes))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3829f0",
   "metadata": {},
   "source": [
    "### Train the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609e5220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_squared_error(y_true, y_pred):\n",
    "    return K.sum(K.square(y_pred - y_true), axis=-1)\n",
    "\n",
    "model.compile(loss=sum_squared_error,\n",
    "                  optimizer='Adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=2,\n",
    "              validation_data=(x_val, y_val),\n",
    "              shuffle=True,\n",
    "              )\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(f'Test loss: { score[0]:.3f}')\n",
    "print(f'Test accuracy: {score[1] * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2477a1b2",
   "metadata": {},
   "source": [
    "### Report the Confusion Matrix of the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf299e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred_vals = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred_vals, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e4b519",
   "metadata": {},
   "source": [
    "### Serialize Model and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82393d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(os.path.join(PATH, 'model.json'), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(os.path.join(PATH, 'model.h5'))\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9211fd0b",
   "metadata": {},
   "source": [
    "We are all done training the plain network. Next we will encrypt the network and run inference over it using FHE. Let's start with some initializations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee4130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhelayers\n",
    "import utils\n",
    "\n",
    "utils.verify_memory()\n",
    "\n",
    "print('Misc. initializations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd942b0e",
   "metadata": {},
   "source": [
    "The following is a general outline of the next steps.\n",
    "\n",
    "We encode and encrypt a neural network model, using the files that were created and saved before. An automated optimizer, that occurs during the call to encode_encrypt, will examine our network and will determine various configuration details that will allow running inference under encryption efficiently.\n",
    "\n",
    "Next, we will demonstrate how we can encrypt data, run inference on our encrypted network, and compare the results against the expected labels.\n",
    "Now let's dive in . . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e11341",
   "metadata": {},
   "outputs": [],
   "source": [
    "he_run_req = pyhelayers.HeRunRequirements()\n",
    "he_run_req.set_he_context_options([pyhelayers.DefaultContext()])\n",
    "he_run_req.optimize_for_batch_size(16)\n",
    "\n",
    "nn = pyhelayers.NeuralNet()\n",
    "nn.encode_encrypt([os.path.join(PATH, \"model.json\"), os.path.join(PATH, \"model.h5\")], he_run_req)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edbc4be",
   "metadata": {},
   "source": [
    "The encode_encrypt method also initialized an HeContext object containing the keys. We obtain it now from the model so we can encrypt the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1730768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = nn.get_created_he_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91afd062",
   "metadata": {},
   "source": [
    "We will now load real samples of the MNIST dataset to classify. We will load the samples and the corresponding true labels from HDF5 files. We will also extract the first batch of samples and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb16a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(PATH, \"x_test.h5\")) as f:\n",
    "    x_test = np.array(f[\"x_test\"])\n",
    "with h5py.File(os.path.join(PATH, \"y_test.h5\")) as f:\n",
    "    y_test = np.array(f[\"y_test\"])\n",
    "    \n",
    "plain_samples, labels = utils.extract_batch(x_test, y_test, batch_size, 0)\n",
    "\n",
    "print('Batch of size',batch_size,'loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a4eee5",
   "metadata": {},
   "source": [
    "To populate the input, we need to encode and then encrypt the values of the plain input under HE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8a882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_io_encoder = pyhelayers.ModelIoEncoder(nn)\n",
    "samples = pyhelayers.EncryptedData(context)\n",
    "model_io_encoder.encode_encrypt(samples, [plain_samples])\n",
    "print('Test data encrypted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59df1642",
   "metadata": {},
   "source": [
    "We now go ahead with the inference itself. We run the encrypted input through the encrypted NN to obtain encrypted results. This computation does not use the secret key and acts on completely encrypted values. Running the inference is done using the \"predict\" method of the NN, that receives the destination 3D structure to put the result of the computation in, and the input for the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f4d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.start_timer()\n",
    "\n",
    "predictions = pyhelayers.EncryptedData(context)\n",
    "nn.predict(predictions, samples)\n",
    "\n",
    "duration=utils.end_timer('predict')\n",
    "utils.report_duration('predict per sample',duration/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ecf2a9",
   "metadata": {},
   "source": [
    "In order to assess the results of the computation, we first need to decrypt them. This is done by an IO processor that has the secret key and is capable of decrypting the ciphertext and decoding it into plaintext version of the HE computation result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17629ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_predictions = model_io_encoder.decrypt_decode_output(predictions)\n",
    "print('predictions',plain_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d884b6a5",
   "metadata": {},
   "source": [
    "Now we compare the results against the expected labels and compute the confusion matrix and the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3258d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.assess_results(labels, plain_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae69f9e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "References:\n",
    "\n",
    "<sub><sup> 1.\tLeCun, Yann and Cortes, Corinna. \"MNIST handwritten digit database.\" (2010): </sup></sub>\n",
    "\n",
    "<sub><sup> 2.\tGilad-Bachrach, R., Dowlin, N., Laine, K., Lauter, K., Naehrig, M. &amp; Wernsing, J.. (2016). CryptoNets: Applying Neural Networks to Encrypted Data with High Throughput and Accuracy. Proceedings of The 33rd International Conference on Machine Learning, in Proceedings of Machine Learning Research 48:201-210 Available from https://proceedings.mlr.press/v48/gilad-bachrach16.html.\n",
    "</sup></sub>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
