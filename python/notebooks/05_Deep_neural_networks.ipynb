{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Networks Inference Using FHE\n",
    "\n",
    "## Introduction\n",
    "This notebook demonstrates running inference of deep neural networks under FHE, where the neural networks demonstrated are AlexNet, SqueezeNet and ResNet-18.\n",
    "\n",
    "AlexNet is the name of a convolutional neural network which has had a large impact on the field of machine learning, specifically in the application of deep learning to machine vision. This is a complicated data science use case for image classification using an FHE-encoded AlexNet neural network with 5 convolutional layers and 3 fully connected layers. As you can see, there is not a lot of code required to perform this under FHE.\n",
    "\n",
    "SqueezeNet and ResNet-18 are additional convolutional neural networks with 26 and 20 convolutional layers, respectively, organized as a non-sequential graph.\n",
    "\n",
    "#### Note: running this demo requires up to ~80GB, ~100GB and ~150GB of available RAM for AlexNet, SqueezeNet and ResNet-18, respectively.\n",
    "\n",
    "#### Note: the prediction part of this demo is expected to last ~3:30, ~8:45 and ~16:00 minutes for AlexNet, SqueezeNet and ResNet-18, respectively, with 88 CPUs.\n",
    "\n",
    "## Use case\n",
    "A potential use case in the healthcare domain using the AlextNet demo is encrypted disease detection or genetic risk prediction using a cloud service. A hospitalâ€™s data center is unlikely to match the scalability and efficiency of a cloud service, particularly in hosting workloads for large clinical trials for complex genetic diseases. However, due to privacy risks and healthcare regulations, it is often impractical for hospitals to make the transition to cloud. FHE in clinical research can improve the acceptance of data-sharing protocols, increase sample sizes and accelerate learning from real-world data. Encrypted image classification can be performed in the cloud service environment to determine if a patient has a specific health issue or disease given an encrypted data set sent by the hospital."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo uses SEAL backend since release 1.5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "References:\n",
    "\n",
    "<sub><sup> Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E. \"Imagenet classification with deep convolutional neural networks\", Advances in neural information processing systems 25, 2012. </sup></sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Step 1. Encoded deep neural network model (with plaintext weights)\n",
    "\n",
    "#### 1a. Import and initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import psutil\n",
    "import utils\n",
    "import pyhelayers\n",
    "\n",
    "input_dir = utils.get_data_sets_dir() + '/' # for the model architecture file\n",
    "\n",
    "model_architecture = 'AlexNet'\n",
    "# model_architecture = 'SqueezeNet'\n",
    "# model_architecture = 'ResNet-18'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1b. Load the network model with random weights and encode it using helayers\n",
    "\n",
    "We specify some hyper parameters that control the randomness of the weights. We also create `HeRunRequirements` that include some additional parameters to run the model with. Finally, we encode a NeuralNetwork model that depends on the specified hyper parameters and HE run requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = pyhelayers.PlainModelHyperParams()\n",
    "hyper_params.init_random_weights = True\n",
    "hyper_params.min_rand_value = -0.1\n",
    "hyper_params.max_rand_value = 0.1\n",
    "hyper_params.sparse_rate = 0.5\n",
    "hyper_params.verbose = True\n",
    "\n",
    "if model_architecture == 'AlexNet':\n",
    "    utils.verify_memory(min_memory_size=90)\n",
    "    input_file = [input_dir + \"net_alex/model_same_padding.json\"]\n",
    "elif model_architecture == 'SqueezeNet':\n",
    "    utils.verify_memory(min_memory_size=120)\n",
    "    input_file = [input_dir + \"squeeze_net/model.onnx\"]\n",
    "elif model_architecture == 'ResNet-18':\n",
    "    utils.verify_memory(min_memory_size=180)\n",
    "    input_file = [input_dir + \"res_net_18/model.onnx\"]\n",
    "\n",
    "he_run_req = pyhelayers.HeRunRequirements()\n",
    "# Request a SEAL context\n",
    "he_run_req.set_he_context_options([pyhelayers.HeContext.create([\"SEAL_CKKS\"])])\n",
    "he_run_req.set_model_encrypted(False)\n",
    "he_run_req.set_lazy_mode(pyhelayers.LazyMode.LAZY_ENCODING)\n",
    "\n",
    "nn = pyhelayers.NeuralNet()\n",
    "nn.encode(input_file, he_run_req, hyper_params)\n",
    "context = nn.get_created_he_context()\n",
    "batch_size = nn.get_profile().get_optimal_batch_size()\n",
    "\n",
    "print(\"Loaded and encoded the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Part 2. Encoded deep Neural Network Model\n",
    "\n",
    "#### 2a. Encrypt random input samples\n",
    "We Generate a `ModelIoEncoder` which manages the encryption and decryption of the model's input and output. This model IO encoder is then used to encrypt random input samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_io_encoder = pyhelayers.ModelIoEncoder(nn)\n",
    "samples = pyhelayers.EncryptedData(context)\n",
    "model_io_encoder.encode_encrypt_random_inputs(samples, num_batches=1)\n",
    "print('Encrypted samples ready')\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"Memory consumption (GB): \", process.memory_info().rss / (1000*1000*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 2b. Perform inference under encryption \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictions = pyhelayers.EncryptedData(context)\n",
    "utils.start_timer()\n",
    "nn.predict(predictions, samples)\n",
    "duration=utils.end_timer('predict')\n",
    "\n",
    "print('Prediction done')\n",
    "utils.report_duration('predict per sample',duration/batch_size)\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"Memory consumption (GB): \", process.memory_info().rss / (1000*1000*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 2c. Decrypt results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "plain_predictions = model_io_encoder.decrypt_decode_output(predictions)\n",
    "print('Decrypted predictions ready')\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"Memory consumption (GB): \", process.memory_info().rss / (1000*1000*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(plain_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fhe-py38-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
