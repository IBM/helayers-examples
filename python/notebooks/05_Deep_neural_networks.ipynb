{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Networks Inference Using FHE\n",
    "\n",
    "## Introduction\n",
    "This notebook demonstrates running inference of deep neural networks under FHE, where the neural networks demonstrated are AlexNet, SqueezeNet and ResNet-18.\n",
    "\n",
    "AlexNet is the name of a convolutional neural network which has had a large impact on the field of machine learning, specifically in the application of deep learning to machine vision. This is a complicated data science use case for image classification using an FHE-encoded AlexNet neural network with 5 convolutional layers and 3 fully connected layers. As you can see, there is not a lot of code required to perform this under FHE.\n",
    "\n",
    "SqueezeNet and ResNet-18 are additional convolutional neural networks with 26 and 20 convolutional layers, respectively, organized as a non-sequential graph.\n",
    "\n",
    "#### Note: running this demo requires up to ~80GB, ~100GB and ~150GB of available RAM for AlexNet, SqueezeNet and ResNet-18, respectively.\n",
    "\n",
    "#### Note: the prediction part of this demo is expected to last ~3:30, ~8:45 and ~16:00 minutes for AlexNet, SqueezeNet and ResNet-18, respectively, with 88 CPUs.\n",
    "\n",
    "## Use case\n",
    "A potential use case in the healthcare domain using the AlextNet demo is encrypted disease detection or genetic risk prediction using a cloud service. A hospitalâ€™s data center is unlikely to match the scalability and efficiency of a cloud service, particularly in hosting workloads for large clinical trials for complex genetic diseases. However, due to privacy risks and healthcare regulations, it is often impractical for hospitals to make the transition to cloud. FHE in clinical research can improve the acceptance of data-sharing protocols, increase sample sizes and accelerate learning from real-world data. Encrypted image classification can be performed in the cloud service environment to determine if a patient has a specific health issue or disease given an encrypted data set sent by the hospital."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "References:\n",
    "\n",
    "<sub><sup> Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E. \"Imagenet classification with deep convolutional neural networks\", Advances in neural information processing systems 25, 2012. </sup></sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Step 1. Unencrypted deep neural network model\n",
    "\n",
    "#### 1a. Import and initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import psutil\n",
    "import utils\n",
    "import pyhelayers\n",
    "\n",
    "input_dir = utils.get_data_sets_dir() + '/' # for the model architecture file\n",
    "\n",
    "model_architecture = 'AlexNet'\n",
    "# model_architecture = 'SqueezeNet'\n",
    "# model_architecture = 'ResNet-18'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1b. Load the network model with random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = pyhelayers.PlainModelHyperParams()\n",
    "hyper_params.init_random_weights = True\n",
    "hyper_params.min_rand_value = -0.1\n",
    "hyper_params.max_rand_value = 0.1\n",
    "hyper_params.sparse_rate = 0.5\n",
    "hyper_params.verbose = True\n",
    "\n",
    "nnp = pyhelayers.NeuralNetPlain()\n",
    "\n",
    "if model_architecture == 'AlexNet':\n",
    "    utils.verify_memory(min_memory_size=90)\n",
    "    nnp.init_from_files(hyper_params, [input_dir + \"net_alex/model_same_padding.json\"])\n",
    "elif model_architecture == 'SqueezeNet':\n",
    "    utils.verify_memory(min_memory_size=120)\n",
    "    nnp.init_from_files(hyper_params, [input_dir + \"squeeze_net/model.onnx\"])\n",
    "elif model_architecture == 'ResNet-18':\n",
    "    utils.verify_memory(min_memory_size=180)\n",
    "    nnp.init_from_files(hyper_params, [input_dir + \"res_net_18/model.onnx\"])\n",
    "\n",
    "print(\"Loaded plain model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1c. Compilation (automatic optimizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_run_req = pyhelayers.HeRunRequirements()\n",
    "# Request a HEaaN context if available, or a SEAL context otherwise\n",
    "he_run_req.set_he_context_options([pyhelayers.HeContext.create([\"HEaaN_CKKS\", \"SEAL_CKKS\"])])\n",
    "he_run_req.set_model_encrypted(False)\n",
    "he_run_req.set_lazy_encoding(True)\n",
    "\n",
    "profile = pyhelayers.HeModel.compile(nnp, he_run_req)\n",
    "batch_size = profile.get_optimal_batch_size()\n",
    "print('Profile ready. Batch size=',batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1d. Generate random test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_input_shape = nnp.get_input_shapes_for_predict()[0]\n",
    "plain_input_shape[0] = batch_size\n",
    "\n",
    "plain_samples = np.random.uniform(-0.5, 0.5, plain_input_shape)\n",
    "print(\"Generated random plain samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1e. Initialize context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "context = pyhelayers.HeModel.create_context(profile)\n",
    "print('HE Context ready')\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"Memory consumption (GB): \", process.memory_info().rss / (1000*1000*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Part 2. Encoded deep Neural Network Model\n",
    "\n",
    "#### 2a. Encode the model using FHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "nn = pyhelayers.NeuralNet(context)\n",
    "nn.encode(nnp, profile)\n",
    "print('HE model ready')\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"Memory consumption (GB): \", process.memory_info().rss / (1000*1000*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 2b. Encrypt the input samples with the random image created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "iop = nn.create_io_processor()\n",
    "samples = pyhelayers.EncryptedData(context)\n",
    "iop.encode_encrypt_inputs_for_predict(samples, [plain_samples])\n",
    "print('Encrypted samples ready')\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"Memory consumption (GB): \", process.memory_info().rss / (1000*1000*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 2c. Perform inference under encryption \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictions = pyhelayers.EncryptedData(context)\n",
    "utils.start_timer()\n",
    "nn.predict(predictions, samples)\n",
    "duration=utils.end_timer('predict')\n",
    "\n",
    "print('Prediction done')\n",
    "utils.report_duration('predict per sample',duration/batch_size)\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"Memory consumption (GB): \", process.memory_info().rss / (1000*1000*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 2d. Decrypt results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "plain_predictions = iop.decrypt_decode_output(predictions)\n",
    "print('Decrypted predictions ready')\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "print(\"Memory consumption (GB): \", process.memory_info().rss / (1000*1000*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plain_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
