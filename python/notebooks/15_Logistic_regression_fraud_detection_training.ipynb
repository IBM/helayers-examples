{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression training over encrypted credit card fraud samples\n",
    "\n",
    "expected RAM usage: 6.5 GB  \n",
    "expected runtime: 20 seconds\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This example demonstrates how an encrypted logistic regression (LR) model can be trained in an untrusted environment with encrypted data. Predictions are also carried out in the untrusted public environment for validation of the trained model. Prediction results are encrypted and sent back to the data owner to be decrypted in a trusted environment.\n",
    "\n",
    "The training is done over creditcardfraud dataset  https://www.kaggle.com/mlg-ulb/creditcardfraud [1]-[9]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo uses SEAL backend since release 1.5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Step 1. Load and prepare the dataset in the trusted environment\n",
    "\n",
    "Load and prepare the credit card fraud dataset for encryption in a trusted client environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils \n",
    "utils.verify_memory(min_memory_size=10)\n",
    "\n",
    "load_from_pre_prepared = True\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "if load_from_pre_prepared:\n",
    "    INPUT_DIR = Path(utils.get_data_sets_dir()) / 'logistic_regression_training'\n",
    "else:\n",
    "    INPUT_DIR = Path('data/logistic_regression_training/')\n",
    "\n",
    "file = INPUT_DIR / 'processed_creditcard_balanced_sample.csv'\n",
    "data = pd.read_csv(file, header=0)\n",
    "labels = (data.iloc[:, -1:]).to_numpy(dtype=np.float128)\n",
    "\n",
    "colors = ['r','b']\n",
    "ax = pd.Series(labels.flatten()).value_counts().plot.bar(xlabel=\"Fraud Cases\", ylabel=\"Frequency\", legend=True, color=colors,title=\"Before training\")\n",
    "ax1 = mpatches.Patch(color='b', label='Not Fraud')\n",
    "ax2 = mpatches.Patch(color='r', label='Fraud')\n",
    "ax.legend(handles=[ax1,ax2], loc=\"lower center\")\n",
    "\n",
    "plain_samples = (data.iloc[:, :-1]).to_numpy(dtype=np.float128) \n",
    "batch_size = plain_samples.shape[0]\n",
    "number_of_features = plain_samples.shape[1]\n",
    "\n",
    "nRow, nCol = plain_samples.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns in our dataset.')\n",
    "# data.info(verbose=True, memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Step 2. Initialize model and encrypt data in a trusted envireonment\n",
    "* A LogisticRegression object is initialized\n",
    "* A requirement configuration is supplied to internally determine the most suitable HE parameters\n",
    "* The encryption of the data is carried out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Initialize and encrypt the logistic regression model\n",
    "\n",
    "We can provide some additional `HyperParameters` and `HeRunRequirements` as inputs.\n",
    "\n",
    "The used hyper parameters are:\n",
    "* the number of iterations to be used in training, which is referred to by `hyper_params.number_of_iterations`\n",
    "* the learning rate for training, which is `hyper_params.learning_rate`\n",
    "* the activation used for training is a degree 3 polynomial approximation of the sigmoid function, and is referenced by `pyhelayers.LRActivation.SIGMOID_POLY_3`. \n",
    "\n",
    "In the HE run requirements, we set the batch size and rely on the default values for other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhelayers\n",
    "\n",
    "hyper_params = pyhelayers.PlainModelHyperParams()\n",
    "hyper_params.fit_hyper_params.number_of_epochs = 3\n",
    "hyper_params.fit_hyper_params.learning_rate = 0.1\n",
    "hyper_params.number_of_features = number_of_features\n",
    "hyper_params.trainable = True\n",
    "hyper_params.logistic_regression_activation = pyhelayers.LRActivation.SIGMOID_POLY_3\n",
    "\n",
    "he_run_req = pyhelayers.HeRunRequirements()\n",
    "# Request a SEAL context\n",
    "he_run_req.set_he_context_options([pyhelayers.HeContext.create([\"SEAL_CKKS\"])])\n",
    "he_run_req.optimize_for_batch_size(batch_size)\n",
    "\n",
    "client_lr = pyhelayers.LogisticRegression()\n",
    "client_lr.encode_encrypt(files=[], he_run_req=he_run_req, hyper_params=hyper_params)\n",
    "client_context = client_lr.get_created_he_context()\n",
    "\n",
    "print('logistic regression training initialised')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Encrypt the data in a trusted environment\n",
    "\n",
    "The plaintext samples and labels are encrypted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_io_encoder = pyhelayers.ModelIoEncoder(client_lr)\n",
    "\n",
    "encrypted_inputs = pyhelayers.EncryptedData(client_context)\n",
    "model_io_encoder.encode_encrypt(encrypted_inputs, [plain_samples, labels])\n",
    "print('training data has been encrypted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Save and send\n",
    "We save the encrypted model, the context, and the samples in preparation for sending them to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_buffer = client_lr.save_to_buffer()\n",
    "inputs_buffer = encrypted_inputs.save_to_buffer()\n",
    "\n",
    "# Save the context. Note that this saves all the HE library information, including the \n",
    "# public key, allowing the server to perform HE computations.\n",
    "# The secret key is not saved here, so the server won't be able to decrypt.\n",
    "# The secret key is never stored unless explicitly requested by the user using the designated \n",
    "# method.\n",
    "context_buffer = client_context.save_to_buffer()\n",
    "\n",
    "print('Context, model, and samples saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Step 3. Perform training on a remote server using encrypted data and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Load the labels, samples and context in the server\n",
    "\n",
    "In the server side, we use the previously saved data to prepare the server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_context = pyhelayers.load_he_context(context_buffer)\n",
    "server_lr = pyhelayers.load_he_model(server_context, lr_buffer)\n",
    "server_inputs = pyhelayers.load_encrypted_data(server_context, inputs_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Perform the model training in the cloud/server using encrypted data and encrypted labels\n",
    "\n",
    "We can now run the training of the encrypted data to obtain encrypted trained weights and bias. This computation does not use the secret key and acts on completely encrypted values.\n",
    "\n",
    "**NOTE: the data, the LR model and the results always remain in an encrypted state, even during computation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with utils.elapsed_timer('training', batch_size):\n",
    "    server_lr.fit(server_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Send the trained model back\n",
    "\n",
    "We can now send back the trained model. Note that the entire server side computation does not have the secret key and no values were revealed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_buffer = server_lr.save_to_buffer()\n",
    "print('Trained model saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Step 4. Decrypt the trained model in the trusted environment\n",
    "\n",
    "The encrypted model computed by the server (stored at `predictions_buffer`) can now be decrypted and decoded in the client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the encrypted predictions.\n",
    "client_trained_lr = pyhelayers.load_he_model(client_context, trained_model_buffer)\n",
    "\n",
    "trained_plain = client_trained_lr.decrypt_decode()\n",
    "\n",
    "print('Predictions loaded and decrypted.')\n",
    "print(trained_plain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Step 5. Assess the results\n",
    "\n",
    "Let's assess the results in two ways. First let's run prediction of the trained model and calculate the precision, recall and F1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with utils.elapsed_timer('validation', batch_size) as timer:\n",
    "    plain_predictions = trained_plain.predict([plain_samples])[0]\n",
    "    \n",
    "plain_predictions = plain_predictions.reshape(plain_predictions.shape[0], 1)\n",
    "accuracy = utils.assess_results(labels, plain_predictions)\n",
    "predicted_labels = [1 if i >= 0.5 else 0 for i in plain_predictions]\n",
    "colors = [\"b\", \"r\"]\n",
    "ax = pd.Series(predicted_labels).value_counts().plot.bar(xlabel=\"Fraud Cases\", ylabel=\"Frequency\", legend=True, color=colors,title=\"Validation After Training\")\n",
    "ax1 = mpatches.Patch(color='b', label='Not Fraud')\n",
    "ax2 = mpatches.Patch(color='r', label='Fraud')\n",
    "ax.legend(handles=[ax1,ax2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's train also in plaintext, and compare the model weights and biases. Our plaintext training code is available under the misc folder. \n",
    "Note that it an HE-friendly version of an LR training algorithm: the 'sigmoid' activation is approximated by a polynomial. It produces somewhat lesser accuracy than the standard algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc.logistic_regression_plain import LogisticRegression\n",
    "new_plain = LogisticRegression(n_iters=hyper_params.fit_hyper_params.number_of_epochs)\n",
    "\n",
    "with utils.elapsed_timer('training_baseline', batch_size) as timer:\n",
    "    new_plain.fit(plain_samples, labels)\n",
    "\n",
    "enc_trained_weights=trained_plain.get_weights().flatten()\n",
    "enc_trained_bias=trained_plain.get_bias().flatten()\n",
    "plain_trained_weights=new_plain.weights.flatten()\n",
    "plain_trained_bias=new_plain.bias.flatten()\n",
    "\n",
    "mse1=np.linalg.norm(enc_trained_weights-plain_trained_weights)\n",
    "mse2=np.linalg.norm(enc_trained_bias-plain_trained_bias)\n",
    "\n",
    "print('Mean square error in weights:',mse1)\n",
    "print('Mean square error in bias:',mse2)\n",
    "\n",
    "if (mse1+mse2>1e-3):\n",
    "    raise Exception(\"MSE too large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RAM usage:\", utils.get_used_ram(), \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "References:\n",
    "\n",
    " <sub><sup> 1. Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015 </sup></sub>\n",
    "    \n",
    "<sub><sup> 2. Dal Pozzolo, Andrea; Caelen, Olivier; Le Borgne, Yann-Ael; Waterschoot, Serge; Bontempi, Gianluca. Learned lessons in credit card fraud detection from a practitioner perspective, Expert systems with applications,41,10,4915-4928,2014, Pergamon </sup></sub>\n",
    "\n",
    "<sub><sup> 3. Dal Pozzolo, Andrea; Boracchi, Giacomo; Caelen, Olivier; Alippi, Cesare; Bontempi, Gianluca. Credit card fraud detection: a realistic modeling and a novel learning strategy, IEEE transactions on neural networks and learning systems,29,8,3784-3797,2018,IEEE </sup></sub>\n",
    "\n",
    "<sub><sup> 4. Dal Pozzolo, Andrea Adaptive Machine learning for credit card fraud detection ULB MLG PhD thesis (supervised by G. Bontempi)</sup></sub>\n",
    "\n",
    "<sub><sup> 5. Carcillo, Fabrizio; Dal Pozzolo, Andrea; Le Borgne, Yann-Aël; Caelen, Olivier; Mazzer, Yannis; Bontempi, Gianluca. Scarff: a scalable framework for streaming credit card fraud detection with Spark, Information fusion,41, 182-194,2018,Elsevier </sup></sub>\n",
    "\n",
    "<sub><sup> 6. Carcillo, Fabrizio; Le Borgne, Yann-Aël; Caelen, Olivier; Bontempi, Gianluca. Streaming active learning strategies for real-life credit card fraud detection: assessment and visualization, International Journal of Data Science and Analytics, 5,4,285-300,2018,Springer International Publishing </sup></sub>\n",
    "\n",
    "<sub><sup> 7. Bertrand Lebichot, Yann-Aël Le Borgne, Liyun He, Frederic Oblé, Gianluca Bontempi Deep-Learning Domain Adaptation Techniques for Credit Cards Fraud Detection, INNSBDDL 2019: Recent Advances in Big Data and Deep Learning, pp 78-88, 2019 </sup></sub>\n",
    "\n",
    "<sub><sup> 8. Fabrizio Carcillo, Yann-Aël Le Borgne, Olivier Caelen, Frederic Oblé, Gianluca Bontempi Combining Unsupervised and Supervised Learning in Credit Card Fraud Detection Information Sciences, 2019 </sup></sub>\n",
    "\n",
    "<sub><sup> 9. Yann-Aël Le Borgne, Gianluca Bontempi Machine Learning for Credit Card Fraud Detection - Practical Handbook </sup></sub> \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fhe-py38-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
