{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# XGBoost Inference on the adult Dataset Using FHE\n",
                "Expected RAM usage: 25 GB.\n",
                "Expected runtime: 3-6 minutes.\n",
                "\n",
                "## Introduction\n",
                " \n",
                "This example demonstrates how to perform inference over encrypted data with an XGBoost model. We will work with the UCI-adult dataset [1-2], which predicts whether a person's income level is above 50K a year.\n",
                "First, a plain XGBoost model will be trained on the iris dataset in the clear. Then, the trained XGBoost model will be encrypted and used to run prediction over an encrypted batch of samples from the adult dataset.  \n",
                "This demo demonstrates an advanced feature that enables storing the encrypted XGBoost model in an external storage. This feature may be useful when encrypting a large XGBoost model that might not fit in RAM. Using this feature requires us to use some low-level API, which is demonstrated and explained in the demo."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1. Training a plain XGBoost model\n",
                "We train an XGBoost model with the adult dataset, in plaintext."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.1 Decide whether this demo will be run on GPU\n",
                "Running on GPU is only possible if the used machine has a GPU and helayers was compiled to use GPU. If these conditions are satisfied, changing the flag below to `True` will make the demo run on GPU."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "run_with_gpu = False"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.2. We start with some imports:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import math\n",
                "import os\n",
                "import pyhelayers\n",
                "import shutil\n",
                "from sklearn import datasets\n",
                "from sklearn.model_selection import train_test_split\n",
                "from utils import get_used_ram, get_data_sets_dir\n",
                "from xgboost import XGBClassifier\n",
                "import pandas as pd"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.3. Load the adult dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def preprocess(X, y):\n",
                "    X['marital-status'] = X['marital-status'].str.strip()\n",
                "    X['marital-status'] = X['marital-status'].replace(['Married-civ-spouse','Married-spouse-absent','Married-AF-spouse'], 'Married')\n",
                "    X['marital-status'] = X['marital-status'].replace(['Never-married','Divorced','Separated','Widowed'], 'Single')\n",
                "    X['marital-status'] = X['marital-status'].map({'Married':0, 'Single':1})\n",
                "    X['marital-status'] = X['marital-status'].astype('int')\n",
                "    X = X[['age', 'education-num', 'marital-status', 'hours-per-week', 'capital-loss', 'capital-gain']]\n",
                "    y=y.str.strip().map({'<=50K': 0, '>50K': 1}).astype('int')\n",
                "    return (X, y)\n",
                "    \n",
                "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
                " 'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
                "  'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'label']\n",
                "INPUT_DIR = os.path.join(get_data_sets_dir(), 'uci_adult')\n",
                "\n",
                "train_data = pd.read_csv(os.path.join(INPUT_DIR, \"adult.data\"), names=column_names, header=None,\n",
                " index_col=False, engine='python')\n",
                "X_train = train_data.iloc[:,:-1]\n",
                "y_train = train_data.iloc[:,-1]\n",
                "X_train, y_train = preprocess(X_train, y_train)\n",
                "\n",
                "test_data = pd.read_csv(os.path.join(INPUT_DIR, \"adult.test\"), names=column_names, header=None,\n",
                " index_col=False, skiprows=1, sep=\"[,.]\", engine='python')\n",
                "X_test = test_data.iloc[:,:-1]\n",
                "y_test = test_data.iloc[:,-1]\n",
                "X_test, y_test = preprocess(X_test, y_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.4. Train the XGBoost model\n",
                "We use XGBoost python library to train the XGBoost model with the adult dataset, and dump the resulting model to a JSON file. This JSON file will later be used to initialize the encrypted XGBoost model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "clf = XGBClassifier(eta=0.2, gamma=3.6, max_depth=3,\n",
                " min_child_weight=3, subsample=0.8, objective=\"binary:logistic\",\n",
                " scale_pos_weight=14.978045943588253, eval_metric = \"aucpr\", n_estimators=10)\n",
                "clf.fit(X_train, y_train)\n",
                "model_dir = os.path.join('data', 'adult_xgboost')\n",
                "os.makedirs(model_dir, exist_ok=True)\n",
                "model_path = os.path.join(model_dir, 'xgb.json')\n",
                "clf.save_model(model_path)\n",
                "print('plain XGBoost model saved')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.5 Evaluate the XGBoost model\n",
                "We compute f1 score for the above trained XGBoost. This score will later be compared with the f1-score for the prediction over encrypted data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import f1_score\n",
                "plain_xgb_preds = clf.predict(X_test)\n",
                "f1_plain = f1_score(y_test, plain_xgb_preds)\n",
                "print('plain XGBoost f1 score =', f1_plain)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2. FHE inference\n",
                "In this step, we will encrypt the above trained XGBoost model and the test samples from the adult dataset. The encrypted XGBoost model will be used to run prediction over the encrypted adult samples."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1 Compute the feature ranges\n",
                "Our XGBoost implementaiton requires the users to specify the minimum and maximum values of each feature. Here, we extract this info from the training data and assume it will also be relevant to the test data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_feature_range(col):\n",
                "    return (col.min(), col.max())\n",
                "    \n",
                "feature_ranges = []\n",
                "for col in X_train:\n",
                "    feature_ranges.append(get_feature_range(X_train[col]))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2. Initialize a `PlainXGBoost` object\n",
                "We intialize a `PlainXGBoost` object using the above trained XGBoost model. This object holds the XGBoost weights in the plain and will later be encrypted and used for prediction over encrypted data.\n",
                "The following hyperparameters are used:\n",
                "* `feature_ranges`: Specifies the minimum and maximum possible values of each feature.\n",
                "\n",
                "* `store_thresholds`: If True, the XGBoost object stores all thresholds of all features of the model in the user side, in the plain. This has the advantage of making prediction faster and more accurate.\n",
                "It has the downside of storing additional data on the client side, and doing some additional small pre-processing on the client-side.  \n",
                "NOTE: if the thresholds data is considered sensitive data, do not set this flag to True.\n",
                "\n",
                "* `round_before_storing_thresholds`: In case `storeThresholds` is `True`, decides whether the thresholds should be scaled and rounded before they are stored. Turning this flag on makes close thresholds considered the same one, thus reducing runtime on the account of possibly reducing accuracy.\n",
                "\n",
                "* `number_of_cached_nodes`: Maximum allowed number of nodes that are shared among trees and their results are cached as an optimization. Increasing this parameter may reduce accuracy at the expense of higher memory consumption.\n",
                "\n",
                "* `grep, frep`: Control the accuracy of the comparison approximation in XGBoost prediction. Higher `grep` and `frep` values increase the accuracy at the expense of deeper and slower computation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "hyper_params = pyhelayers.PlainModelHyperParams()\n",
                "hyper_params.feature_ranges = feature_ranges\n",
                "hyper_params.store_thresholds = True\n",
                "hyper_params.round_before_storing_thresholds = True\n",
                "hyper_params.number_of_cached_nodes = 100\n",
                "hyper_params.grep = 2\n",
                "hyper_params.frep = 1\n",
                "plain_xgb = pyhelayers.PlainModel.create(hyper_params, [model_path])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.3 Define HE run requirements\n",
                "These requirements specify how the HE encryption should be configured. Here, we require the HE encryption to be done with HEaaN CKKS encryption scheme."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "he_run_req = pyhelayers.HeRunRequirements()\n",
                "he_run_req.set_he_context_options([pyhelayers.HeaanContext()])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.4 Compile the plain model and HE run requirements into HE profile\n",
                "The compilation produces an HE profile which holds encryption-specific parameters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "profile = pyhelayers.HeModel.compile(plain_xgb, he_run_req)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.5 Initialize the HE context\n",
                "Once the HE profile is ready, we use it to initialize the context. If `run_with_gpu` flag is set, we update the he_context to use a GPU device by default. Otherwise, we use CPU as usual."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "he_context = pyhelayers.HeModel.create_context(profile)\n",
                "if run_with_gpu:\n",
                "    he_context.set_default_device(pyhelayers.DeviceType.DEVICE_GPU)\n",
                "else:\n",
                "    he_context.set_default_device(pyhelayers.DeviceType.DEVICE_CPU)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.6. Initialize the XGBoost model and attach output storage\n",
                "We initialize the HE XGBoost model using the plain model created above. We also attach an output directory to the model. This directory will be used to store the encrypted trees and load them on demand upon prediction. Using an output storage prevents out of memory errors in case the encrypted XGBoost model is too large."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "xgb = plain_xgb.get_empty_he_model(he_context)\n",
                "storage_dir = os.path.join('outputs', 'xgb_storage')\n",
                "os.makedirs(storage_dir, exist_ok=True)\n",
                "fstorage=pyhelayers.FileStorage(storage_dir,create=True)\n",
                "xgb.attach_output_storage(fstorage)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.7 Encrypt the XGboost model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "xgb.encode_encrypt(plain_xgb, profile)\n",
                "print('FHE XGBoost model encrypted and initialized')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.8 Get a `ModelIoEncoder` from the HE XGBoost model.\n",
                "The ModelIoEncoder object will be used to encrypt and decrypt the input and output of the FHE prediction."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_io_encoder = pyhelayers.ModelIoEncoder(xgb)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.9. Encrypt the test samples\n",
                "We encrypt the test samples using the ModelIoEncoder created above."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_test_enc = pyhelayers.EncryptedData(he_context)\n",
                "model_io_encoder.encode_encrypt(X_test_enc, [X_test])\n",
                "print('input data encrypted')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.10 Flush the XGBoost model to the output storage\n",
                "`flush_to_storage()` function stores the XGBoost metadata in the output storage directory."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "xgb.flush_to_storage()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.11 Load the XGBoost model\n",
                "When we encrypted the model and flushed it to the file storage we specified, all the encrypted trees were stored in the folder we specified. This folder can now be moved to a cloud server and used for prediction. Here we simply create a new XGBoost model and attach to it the save folder. Upon prediction, the encrypted trees will be loaded on demand from the file system."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "xgb_server = plain_xgb.get_empty_he_model(he_context)\n",
                "xgb_server.attach_input_storage(fstorage)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.12 Run prediction over the encrypted data\n",
                "We perform FHE prediction on the encrypted test samples, using the encrypted XGBoost model. The resulting predictions are encrypted as well, and will next be decrypted and compared to the expected labels."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "res = pyhelayers.EncryptedData(he_context)\n",
                "xgb_server.predict(res, X_test_enc)\n",
                "print('prediction ready')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3. Decrypt the prediction results\n",
                "We decrypt the prediction results and then convert the predicted float output values to integer labels."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "res_plain = model_io_encoder.decrypt_decode_output(res)\n",
                "res_plain = np.where(res_plain > 0, 1, 0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.1. Evaluate the FHE prediction\n",
                "We compute the f1 score of the FHE prediction and verify that it is very close to the f1 score of the plain prediction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "f1_fhe = f1_score(y_test, res_plain)\n",
                "print('FHE XGBoost f1 score =', f1_fhe)\n",
                "assert(f1_fhe >= f1_plain - 0.1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"RAM usage:\", get_used_ram(), \"MB\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 Remove the output storage directory\n",
                "We remove the directory that was used to store the encrypted trees of the XGBoost"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "shutil.rmtree('outputs')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Citations\n",
                "[1] Kohavi,  R.,  Becker,  B.:   Uci  machine  learning  repository  -  adult  dataset  (1996), https://archive.ics.uci.edu/ml/datasets/adult18.\n",
                "\n",
                "[2] Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "fhe-py38-env",
            "language": "python",
            "name": "fhe-py38-env"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
