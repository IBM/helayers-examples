{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM HElayers\n",
    "\n",
    "\n",
    "![title](img/fhe.jpg)\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why FHE?\n",
    "\n",
    "With business data stored across cloud environments, on a daily basis, we see that it can be exposed to various security risks and vulnerabilities. IBM X-Force Threat Intelligence Index found 8.5 billion records breached in 2019, giving attackers access to more stolen credentials. Securing credentials and access controls is more important than ever.\n",
    "\n",
    "While encryption allows data to be protected both during transit and storage, the data typically must be decrypted while it is being accessed for computing and business-critical operations â€“ creating the opportunity for potential compromise of privacy and confidentiality controls.\n",
    "\n",
    "FHE is a more advanced form of encryption, which is designed to close this gap -- by allowing data to remain encrypted even during computation. The mathematics behind FHE are designed so that computations can be performed on encrypted data (ciphertext), without the service behind it needing to \"see\" that data in order to provide accurate results.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "These tutorials are a set of Jupyter notebooks showcasing different aspects of Fully Homomorphic\n",
    "Encryption(FHE). All of these notebooks present a guided interactive experience and you\n",
    "are encouraged to run these notebooks and try out the different use cases. The goal of these tutorials are to \n",
    "make the user familiar with FHE along with showcasing how the HElayers library can be used to implement FHE in Python.\n",
    "\n",
    "The FHE demos use three backends: SEAL, HELib, and HEaaN. For most demos it is easy to switch between different backends, and explore which works best in each case.\n",
    "<br>\n",
    "<br>\n",
    "**Switch to the Table of Contents view to get the best viewing experience for the notebook.**\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use\n",
    "\n",
    "If you are unfamiliar with Jupyter notebooks, they are self-contained python applications that create a web-based development environment in the browser.  They integrate code, text, formatting, and output into a single document that can be run in inidividual steps or all together in sequence.  \n",
    "\n",
    "Each file that ends in `.ipynb` is considered one notebook.  From the menu on the left, choose a notebook to open by double clicking one.  Each notebook consists of different groups of code that are organized into cells.  A cell can be run by highlighting it, and then clicking the `Run` button, which is notated by the Play icon.  Or, you can run the whole notebook, choose `Run All Cells` from the `Run` menu at the top of the notebook. \n",
    "\n",
    "Some of the notebooks use large data sets when running so they require more memory than what might be set by default.  Please allocate at least 8gb of memory in the Resources tab.  This can be found by navigating to `Docker -> Preferences -> Resources` .  A few demos require more memory, as noted in the beginning of their notebook (in particular, `05_Deep_neural_networks.ipynb` demo may require up to 150 GB of memory).\n",
    "\n",
    "More information about how to set resources can be found on the [docker website](https://docs.docker.com/config/containers/resource_constraints/).  Additionally, you can check out the user manual for windows [https://docs.docker.com/desktop/windows/](https://docs.docker.com/desktop/windows/), or mac [https://docs.docker.com/desktop/mac/](https://docs.docker.com/desktop/mac/) to learn how to allocate resources on the platform you are using.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "\n",
    "#### 1. Basics of FHE [`01_FHE_basics.ipynb`]\n",
    "\n",
    "This covers the basics of **FHE** and showcases how **FHE** can enable us to do tensor mathematics while keeping the computations fully encrypted. It walks through the HElayers library, showcasing how to set it up correctly, and how to use it to carry out basic operations such as addition, multiplication, and rotation all while keeping the data encrypted. \n",
    "\n",
    "\n",
    "#### 2. Neural Network Inference on a Credit Card Fraud Detection Dataset [`02_Neural_network_fraud_detection.ipynb`]\n",
    "\n",
    "This demonstrates the use case where we are leveraging FHE along with Neural Networks(NN). The notebook has a pre-trained model that is assumed to be trained locally in the user's infrastructure. This notebook walks through the steps of\n",
    "\n",
    "- Encrypting the pre-trained NN model such that the weights of the NN are now encrypted \n",
    "- Encrypting the data to be used for inference, such that they test data is also encrypted\n",
    "- Carrying out inference using encrypted data and encrypted NN and getting an encrypted result back\n",
    "- Decrypting the encrypted result back to get the actual result\n",
    "\n",
    "Its purpose is to show that one can encrypt the NN and the data in their local trusted environment and then leverage the power of cloud, by using the cloud, to carry out inference on encrpyted data and encrypted NN. The computations are carried out on encrypted data and data as well as the weights of the NN model remain encrypted throughout the process. Additionally, the results of the computation are encrypted as well. One can then decrypt these results again in their local trusted environment.\n",
    "\n",
    "To be able to run this notebook, you first need to follow and run the notebook that generates a trained model on the plain text data. This notebook can be found under `data_gen/fraud_detection_demo.ipynb`.\n",
    "\n",
    "#### 3. Logistic Regression Inference on a Credit Card Fraud Detection Dataset [`03_Logistic_regression_fraud_detection.ipynb`]\n",
    "\n",
    "This notebook showcases how you can use FHE with logistic regression. It is done by encrypting a logistic regression based model that was trained in a trusted environment, along with encrypting the data that will be used to carry out the inference. Predictions can then be carried out in a public cloud environment, while data and computations remain encrypted along with the results. The results can then be decrypted in a trusted environment. \n",
    "\n",
    "To be able to run this notebook, you first need to follow and run the notebook that generates a trained model on the plain text data. This notebook can be found under `data_gen/fraud_detection_lr_demo.ipynb`.\n",
    "\n",
    "#### 4. Text Classification [`04_Text_classification.ipynb`]\n",
    "\n",
    "This tutorial displays text classification under FHE using a neural network.\n",
    "\n",
    "#### 5. Deep Neural Networks [`05_Deep_neural_networks.ipynb`]\n",
    "\n",
    "This classifies 224 x 224 pixel RGB images using deep neural netowrks: Alex-Net, Squeeze-Net or Res-Net-18.\n",
    "<br>\n",
    "<br>\n",
    "**NOTE:** This tutorial requires up to 150 GB memory and may not run on all machines.\n",
    "\n",
    "#### 6. Country / Capital Database Search [`06_Database_search.ipynb`]\n",
    "\n",
    "This tutorial demostrates encrypted query over an encrypted database.  It uses the BGV scheme, and Fermat's little theorem to compute equality over the modular arithmetic supplied by the scheme.\n",
    "\n",
    "#### 7. K-means Nearest Neighbor [`07_Kmeans.ipynb`]\n",
    "\n",
    "This illustrates how to encrypt a set of centroids, and find nearest neighbor under HE.  Given a set of encrypted samples, we compute the distance between each sample and each centroid under encryption. On the client side, the results are decrypted and automatically post-processed to obtain the nearest neighbor.\n",
    "\n",
    "#### 8. Linear Regression [`08_Linear_regression.ipynb`]\n",
    "\n",
    "This computes linear regression using an encrypted model and data.\n",
    "\n",
    "#### 9. Neural Network Inference on the MNIST Dataset [`09_Neural_network_MNIST.ipynb`]\n",
    "\n",
    "This notebook demonstrates how to build a NN encrypted under FHE, and run inference of encrypted samples from the MNIST dataset.\n",
    "\n",
    "#### 10. Neural Network Inference on Heart Disease UCI medical Dataset [`10_Neural_network_heart_disease.ipynb`]\n",
    "\n",
    "This demonstrates how to build a NN encrypted under FHE, and run inference of encrypted samples from a dataset of patients and their medical information.  The purpose is to detect a potential heart attack. \n",
    "To be able to run this notebook, you first need to follow and run the notebook that generates a trained model on the plain text. This notebook can be found under  *TODO: add path*\n",
    "The dataset can be downloaded from: https://www.kaggle.com/ronitf/heart-disease-uci\n",
    "\n",
    "#### 11. Tile Tensor [`11_Tile_tensor.ipynb`]\n",
    "\n",
    "Tile tensors are useful tools for handling tensors in a packing oblivious way.\n",
    "\n",
    "This tutorial has code examples that help show how to encrypt, decrypt and perform basic operations using tile tensors.\n",
    "\n",
    "See a more extensive tutorial with 3 additional notebooks in subfolder tile_tensors, explaining the tile tensor concept in detail.\n",
    "\n",
    "#### 12. Logistic Regression Inference on a Credit Card Fraud Detection Dataset [`12_Pyhelayers_ext_Logistic_regression_fraud_detection.ipynb`] \n",
    "#### 13. Neural Network Inference on a Credit Card Fraud Detection Dataset [`13_Pyhelayers_ext_Neural_network_fraud_detection.ipynb`]\n",
    "\n",
    " These notebooks demonstrate the pyhelayers.ext api, which offers an easy integration with the scikit-learn/keras libraries. It replaces the scikit-learn/keras predictions with the FHE implementation. The FHE configuration details are taked from fhe.json configuration file.\n",
    " This config file contains FHE parameters that the user can tune (e.g. batch size, security level, etc.).\n",
    "\n",
    "#### 14. NN inference for detecting Covid19 from CT image [`14_COVID_inference.ipynb`]\n",
    "This tutorial demonstrates a NN with 3 convolutional and 2 fully-connected layers for detecting Covid19 from CT image with non-trivial size of 224x224x3 in a secure way.\n",
    "\n",
    "#### 15. Logistic regression training over encrypted data[`15_Logistic_regression_fraud_detection_training.ipynb`]\n",
    "This tutorial demo the training of logistic regression with encrypted samples from Kaggle's creditcardfraud dataset.\n",
    "\n",
    "#### 16. Completely Random Forest training over encrypted data [`16_Complete_random_forest_training.ipynb`]\n",
    "This tutorial demo the training process of a Completely Random Forest model with encrypted samples from UCI's Adult dataset.\n",
    "\n",
    "#### 17. Entity Resolution [`17_Entity_resolution.ipynb`]\n",
    "This tutorial demonstrates the Entity Resolution process using a Privacy Preserving Record Linkage (PPRL) Protocol between two parties.\n",
    "\n",
    "#### 18. ARIMA training and prediction on encrypted data [`18_ARIMA.ipynb`]\n",
    "This tutorial demonstrates an ARIMA model training and prediction on encrypted data.\n",
    "\n",
    "#### 19. MLToolbox demonstration [`19_MLToolbox.ipynb`]\n",
    "This tutorial demonstrates how MLToolbox can be used to convert a NN into an FHE-Friendly model with nearly the same performance, that can later be encrypted and used for prediction on encrypted data.\n",
    "\n",
    "#### 20. XGBoost prediction on encrypted data [`20_XGBoost_prediction.ipynb`]\n",
    "This tutorial demonstrates how to perform prediction over encrypted data with an XGBoost model.\n",
    "\n",
    "#### 21. One-Hot demonstration [`21_One_hot_encoding.ipynb`]\n",
    "This tutorial demonstrates calculation of one-hot encoding under homomorphic encryption.\n",
    "\n",
    "#### 22. Private Set Intersection for Vertical Federated Learning demo [`22_PSI_federated_learning.ipynb`]\n",
    "This tutorial demonstrates a Private Set Intersection process between three parties to be used for Vertical Federated Learning.\n",
    "\n",
    "#### 23. Multi-Party FHE demo [`23_Multi_Party_FHE.ipynb`]\n",
    "This tutorial demonstrates a use of a multi-party FHE setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
