{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLToolbox demonstration\n",
    "Expected RAM usage: 40 GB.\n",
    "Expected runtime: 90 minutes.\n",
    "\n",
    "NVIDIA A100-SXM4-40GB, 10cpu: 14 minutes\n",
    "\n",
    "Note that it is possible to run the notebook on different hardware. When multiple GPUs are available the notebook will automatically utilize them, to speed up the computation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This demo notebook focuses on preparing a model for efficient use with Fully Homomorphic Encryption (FHE) using MLToolbox. MLToolbox offers specialized tools that make models FHE-friendly while minimizing performance degradation. Let's delve into the process of making models FHE-friendly and learn how MLToolbox simplifies this task.\n",
    "\n",
    "Note: \n",
    " -  Currently supported models: AlexNet, LeNet5, Squeezenet, SqueezenetCHET, ResNet18, ResNet50, ResNet101, ResNet152 and CLIP-RN50. To learn how to add a new model, please refer to: `help(nn_module)`.\n",
    " -  Supported datasets: CIFAR10, CIFAR100, COVID_CT, COVID_XRAY, Places205, Places365 and ImageNet. To add a new dataset, please see `help(DatasetWrapper)`.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Step 1. Training the original model](#train)            \n",
    "* [Step 2. Transforming the original model into an intermediate, range-aware form](#intermidate)   \n",
    "* [Step 3. Transforming the range-aware form into an FHE-Friendly form](#polynomial)   \n",
    "* [Step 4. Encrypting the trained model and predicting over encrypted data](#encrypt)        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train\"></a>\n",
    "## Step 1. Training the base model\n",
    "\n",
    "In this step, we will train the base model using MLToolbox. This base model will serve as the starting point for the gradual conversion process we will undertake later.\n",
    "\n",
    "Note: If you already have a pre-trained model, you can skip this step. Simply ensure that the model is saved as demonstrated in [the steps below](#save)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Start with some imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#Printing only error debug printouts\n",
    "os.environ[\"LOG_LEVEL\"]=\"ERROR\"\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import utils # used for benchmarking\n",
    "#trange used to show progress of training loops\n",
    "from tqdm.notebook import trange\n",
    "#magic function that renders the figure in a notebook\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "#FHE related import\n",
    "import pyhelayers\n",
    "#mltoolbox imports\n",
    "from pyhelayers.mltoolbox.arguments import Arguments\n",
    "import pyhelayers.mltoolbox.utils.util as util\n",
    "from pyhelayers.mltoolbox.poly_activation_converter import starting_point\n",
    "from pyhelayers.mltoolbox.data_loader.ds_factory import DSFactory\n",
    "from pyhelayers.mltoolbox.model.DNN_factory import DNNFactory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Initialize the trainer object.\n",
    "In the following cell, we initialize the `Arguments` class. This class defines the default values for various parameters related to the training process, allowing for their customization. \n",
    "`model`,`dataset_name`, `num_epochs`, `classes` and `data_dir` are required arguments, that do not have defaults.\n",
    "The `data_dir` argument specifies the dataset location.\n",
    "\n",
    "For tutorial efficiency reasons, we used a short training duration of 25 epochs, and argue that using more epochs (and maybe other hyper-parameters) would achieve better accuracy.\n",
    "\n",
    "MLToolbox uses a fixed seed by default, to ensure reproducibility. Randomicity is achieved by setting `args.seed` to different values. Still fluctuations in the results are possible, when running the code on a different architecture.\n",
    "\n",
    "The `starting_point` method receives the user arguments and returns two objects: `trainer` and `poly_activation_converter`, which will assist in converting the original model into an FHE-friendly form using the following steps.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments(model=\"lenet5\", dataset_name=\"CIFAR10\", num_epochs=25, classes=10, data_dir = 'cifar_data')\n",
    "\n",
    "#After initializing an `Argument` object it is possible to customize its settings\n",
    "args.lr=0.001\n",
    "args.batch_size = 200\n",
    "\n",
    "#Use the following line to utilize the arguments:\n",
    "trainer, poly_activation_converter, _ = starting_point(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.get_model()\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The supported datasets can be observed using the following call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSFactory.print_supported_datasets()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The supported models can be observed using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNNFactory.print_supported_models()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Training the original model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training loop using the trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = trange(1,args.num_epochs + 1)\n",
    "\n",
    "#This list will accumulate the validation accuracy for each epoch, so we can later plot it\n",
    "val_acc = []\n",
    "scheduler = ReduceLROnPlateau(trainer.get_optimizer(), factor=0.5, patience=2, min_lr=0.000001, verbose=True)\n",
    "for epoch in epochs_range:\n",
    "        trainer.train_step(args, epoch, epochs_range)\n",
    "        val_metrics, val_cf = trainer.validation(args, epoch) # perform validation. Returns metrics (val_metrics) and confusion matrix (val_cf)\n",
    "        val_acc.append(val_metrics.get_avg('accuracy'))\n",
    "        \n",
    "        scheduler.step(val_metrics.get_avg('loss'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the test metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics, test_cf = trainer.test(args, epoch)\n",
    "print({'loss': test_metrics.get_avg('loss'), 'accuracy': test_metrics.get_avg('accuracy')})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a trained model that can be converted to the FHE-friendly form later on. The accuracy of this model is 0.65, which can be improved upon training for some more epochs. Once the model is ready, we save it to a file for future use: \n",
    "\n",
    "<a id=\"save\"></a> \n",
    "Note: as mentioned earlier, you don't have to use a model trained with MLToolbox. You can use a pre-trained model and skip Step 1 of this notebook â€“ just make sure your model is saved in the supported form `{'model': model}` as shown below, and that it is supported by mltoolbox, or extended:\n",
    "\n",
    "`state = {'model': model}\n",
    "torch.save(state, file_name)`\n",
    "\n",
    "Below we save the model we just trained as a checkpoint. The save location is defined by the args.save_dir argument. The default value is set to `outputs/mltoolbox`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.save_model(trainer, poly_activation_converter, args, val_metrics, epoch, val_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(val_acc):\n",
    "    plt.plot([*range(1, args.num_epochs + 1)], val_acc)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xticks(np.arange(1,args.num_epochs + 1,step=2)) \n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot(val_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Replacing max-pooling\n",
    "\n",
    "FHE does not natively support max pooling operations. To address this limitation, we replace max pooling with average pooling. There are two approaches to accomplish this: 1) by training the base model from scratch with average pooling; 2) by converting the pooling operation to average pooling after the model has been trained, and then continuing training for a few additional epochs. To configure MLToolbox to option #2, set the `pooling_type` argument before running the `starting_point` and training steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.pooling_type = \"avg\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intermidate\"></a>\n",
    "## Step 2. Transforming the original model into an intermediate, range-aware form"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we aim to minimize the input range to the non-polynomial activation layers. Particularly, this process involves the ReLU activation layers keeping track of the input range. Additionally, a regularization term is added to the network, penalizing values that fall outside of this range.\n",
    "\n",
    "There are two primary reasons for performing this step:\n",
    "\n",
    "- To enable the approximation of activations by polynomials, it is essential to provide the range of inputs to the activation function beforehand.\n",
    "- Our goal is to optimize the input range for more accurate activation approximation using low-degree polynomials. While we use the interval [-10, 10] as an example, the actual range depends on the specific model and data. It is preferable to have a smaller range to achieve a more precise approximation. However, a significantly larger range could negatively impact the accuracy of the polynomial model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Define the arguments to represent what we want to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.pooling_type = \"avg\"\n",
    "args.activation_type= \"relu_range_aware\"\n",
    "args.num_epochs = 12\n",
    "args.lr=0.001\n",
    "args.from_checkpoint = \"outputs/mltoolbox/lenet5_last_checkpoint.pth.tar\"\n",
    "args.range_awareness_loss_weight=0.01\n",
    "args.range_aware_train = True\n",
    "args.save_dir = \"outputs/mltoolbox/range_aware\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `args.pooling_type = \"avg\"`: All the pooling operations will be replaced by average-pooling (the default is `\"max\"`, in which case the pooling layers are not replaced).\n",
    "\n",
    "* `args.activation_type=\"relu_range_aware\"`: The Relu activations will be account for it's input range (other options are `'trainable_poly'`, `'non_trainable_poly'`, `'approx_relu'`, `'relu'`, `'weighted_relu'`, `'relu_range_aware'`,`'square'`).\n",
    "\n",
    "* `args.num_epochs=12`: The number of epochs to train\n",
    "\n",
    "* `args.lr=0.001`: Learning rate\n",
    "\n",
    "* `args.from_checkpoint = \"outputs/mltoolbox/lenet5_last_checkpoint.pth.tar\"`: The checkpoint to load the model from.\n",
    "\n",
    "* `args.range_awareness_loss_weight=0.01`: This is the weight that defines how much attention is given to diminishing the ranges during training, relatively to the CrossEntropyLoss. This value needs to be tuned for the used model and data such that the training does not suffer from too hursh accuracy degradation.\n",
    "\n",
    "* `args.range_aware_train=True`: A flag that makes the training be range aware. Can be turned off.\n",
    "\n",
    "* `args.save_dir = \"outputs/mltoolbox/range_aware\"`: The directory where the output of this step will be saved"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Run starting_point again, with the new arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer, poly_activation_converter, epoch = starting_point(args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Transform and train the range-aware model\n",
    "\n",
    "We train the model for several more epochs. At the beginning of the training loop, the `replace_activations` function handles anything that needs to be replaced in the current epoch. Then, the train step is called. This is the same train step we ran before; the only difference is that the loss function will now have an extra term that will regulize the input, striving to bring them towards the required range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = []\n",
    "ranges_train = []\n",
    "ranges_val = []\n",
    "scheduler = ReduceLROnPlateau(trainer.get_optimizer(), factor=0.5, patience=2, min_lr=args.min_lr, verbose=True)\n",
    "epochs_range = trange(1,args.num_epochs + 1)\n",
    "\n",
    "for epoch in epochs_range:\n",
    "    poly_activation_converter.replace_activations(trainer, epoch, scheduler)\n",
    "    trainer.train_step(args, epoch, epochs_range)\n",
    "    ranges_train.append(trainer.get_all_ranges(args))\n",
    "    \n",
    "    val_metrics, val_cf = trainer.validation(args, epoch) # perform validation. Returns metrics (val_metrics) and confusion matrix (val_cf)\n",
    "    val_acc.append(val_metrics.get_avg('accuracy'))\n",
    "    ranges_val.append(trainer.get_all_ranges(args))\n",
    "    \n",
    "util.save_model(trainer, poly_activation_converter, args, val_metrics, epoch, val_cf)\n",
    "\n",
    "test_metrics, test_cf = trainer.test(args, epoch)\n",
    "print({'loss': test_metrics.get_avg('loss'), 'accuracy': test_metrics.get_avg('accuracy')})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting range-aware model that we trained exhibits an overall accuracy of 0.67. This accuracy slightly surpasses that of the original model because we did not fully optimize the original model during training, allowing further improvements in the current step. We set the `range_aware_weight` relatively low in this attempt, since the ranges are not too high, to begin with. When running your model, the `range_aware_weight` should be carefully tuned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer.get_model())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's observe the ranges of the model's activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ranges(ranges):\n",
    "    num_epochs = len(ranges)\n",
    "    num_items = len(ranges[num_epochs-1])\n",
    "\n",
    "    # Select a specific color map\n",
    "    color_map = cm.get_cmap('tab10')\n",
    "    start_epoch = next((i for i, epoch in enumerate(ranges) if epoch), None)\n",
    "    \n",
    "    if start_epoch is None:\n",
    "        print(\"No ranges data found.\")\n",
    "        return\n",
    "    \n",
    "    num_epochs_to_plot = num_epochs - start_epoch\n",
    "    for item_index in range(num_items):\n",
    "        min_values = [epoch[item_index][0] for epoch in ranges[start_epoch:]]\n",
    "        max_values = [epoch[item_index][1] for epoch in ranges[start_epoch:]]\n",
    "        # Generate color index based on item index\n",
    "        color_index = item_index % color_map.N\n",
    "        \n",
    "        plt.plot(range(num_epochs_to_plot), min_values, label=f'Min- {item_index+1}', color=color_map(color_index))\n",
    "        plt.plot(range(num_epochs_to_plot), max_values, label=f'Max- {item_index+1}', color=color_map(color_index))\n",
    "\n",
    "    #plt.legend(loc='upper right')  # Display legend\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Epoch')  # Set x-axis label\n",
    "    plt.ylabel('Value')  # Set y-axis label\n",
    "    plt.title('Minimum and Maximum Values over Epochs')  # Set plot title\n",
    "    \n",
    "    # Set x-axis limits to start from start_epoch\n",
    "    plt.xlim(start_epoch, num_epochs_to_plot)\n",
    "    \n",
    "    plt.show()  # Display the plot\n",
    "    \n",
    "plot_ranges(ranges_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_ranges(ranges_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ranges are around [-10,10], no need to make them smaller then this. If we wanted to, we could enlarge the args.range_awareness_loss_weight to turn more attention to diminishing the ranges, or try training this range step for more epochs to have slow gradual change."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"polynomial\"></a>\n",
    "## Step 3. Transforming the range-aware form into an FHE-Friendly form"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Relu activations are replaced according to the arguments we've defined.\n",
    "We start with a partially transformed model; the pooling type is already average, and some batch normalization may have been added.\n",
    "Relu is replaced by a non-trainable polynomial, that approximate the RELU in the range that it holds. The remaining epochs are used to improve the model with no additional changes.\n",
    "\n",
    "At the beginning of the training loop, the replace_activations function handles anything that needs to be replaced in the current epoch. Then, the train step is called. This is the same train step we ran before; the only difference is that the loss function has an extra term that regulizes the inputs in the required range.\n",
    "\n",
    "After the training loop has completed, we save the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.pooling_type = \"avg\"\n",
    "args.activation_type= \"non_trainable_poly\"\n",
    "args.num_epochs = 20 #10 can be enough\n",
    "args.lr=0.001\n",
    "args.from_checkpoint = \"outputs/mltoolbox/range_aware/lenet5_best_checkpoint.pth.tar\"\n",
    "args.range_awareness_loss_weight=0.1\n",
    "args.range_aware_train = True\n",
    "args.save_dir = \"outputs/mltoolbox/polynomial\"\n",
    "\n",
    "trainer, poly_activation_converter, epoch = starting_point(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = []\n",
    "ranges_train = []\n",
    "ranges_val = []\n",
    "scheduler = ReduceLROnPlateau(trainer.get_optimizer(), factor=0.5, patience=2, min_lr=args.min_lr, verbose=True)\n",
    "epochs_range = trange(1,args.num_epochs + 1)\n",
    "\n",
    "for epoch in epochs_range:\n",
    "    poly_activation_converter.replace_activations(trainer, epoch, scheduler)\n",
    "    trainer.train_step(args, epoch, epochs_range)\n",
    "    ranges_train.append(trainer.get_all_ranges(args))\n",
    "    \n",
    "    val_metrics, val_cf = trainer.validation(args, epoch) # perform validation. Returns metrics (val_metrics) and confusion matrix (val_cf)\n",
    "    val_acc.append(val_metrics.get_avg('accuracy'))\n",
    "    ranges_val.append(trainer.get_all_ranges(args))\n",
    "    \n",
    "util.save_model(trainer, poly_activation_converter, args, val_metrics, epoch, val_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(val_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting accuracy we got is 0.66, which is above the accuracy we started with (of the base model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ranges(ranges_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ranges(ranges_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Convert the model into onnx format.\n",
    "The fhe_best checkpoint, that was saved by util.save_model is read and the model is converted into onnx (some format changes are applyed to the model during the convertion.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path, model = util.save_onnx(args, poly_activation_converter, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below table summarizes the results achieved in this notebook:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Technique    | Accuracy   | \n",
    "|:-------------|:-----------|\n",
    "| **ReLU**     | **0.66**       |\n",
    "| range-aware polynomial  | 0.66     |\n",
    "\n",
    "*With more training we were able to achieve accuracy of above 0.9 for both ReLU and polynomial model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"encrypt\"></a>\n",
    "## Step 4. Encrypting the model and predicting over encrypted data\n",
    "We now encrypt the FHE-friendly model trained above and use the encrypted model to make predictions on encrypted data. We'll also make predictions using the plain (unencrypted) model, and compare the two sets of results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Extract a batch from the validation set\n",
    "First, we extract a batch from the validation set. This is the data we'll run and compare the encrypted and plain models on. We set the batch size to smaller value, so that the encrypted prediction runs faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 10\n",
    "trainer, poly_activation_converter, epoch = starting_point(args)\n",
    "\n",
    "plain_samples, labels = next(iter(trainer.val_generator))\n",
    "batch_size = len(plain_samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Perform prediction using the plain model trained above\n",
    "We load the best computed checkpoint of the plain model and use it to run predictions over the batch extracted above.\n",
    "The resulting labels are computed as the argmax of the predicted probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(os.path.join('outputs/mltoolbox/polynomial/lenet5_best_checkpoint.pth.tar'))\n",
    "model = checkpoint['model']\n",
    "plain_model_predictions = model(plain_samples).detach().numpy()\n",
    "plain_predicted_labels = np.argmax(plain_model_predictions, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Load NN architecture and weights using the FHE library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `init_from_onnx_file` function of the `NeuralNetPlain` class to load the NN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'outputs/mltoolbox/polynomial/lenet5.onnx'\n",
    "nnp = pyhelayers.NeuralNetPlain()\n",
    "hyper_params = pyhelayers.PlainModelHyperParams()\n",
    "nnp.init_from_files(hyper_params,[model_path])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Compile\n",
    "\n",
    "Using HE can require configuring complex and non-intuitive parameters. Luckily, helayers has an `Optimizer` tool offers an automatic optimization process that analyzes the model, and tunes various HE parameters to work best for the given scenario.\n",
    "\n",
    "The optimizer runs when we run 'compile' on the plain model. It receives also run requirements, some simple and intuitive input from the user (e.g., the desired security level). As output, it produces a `profile` object which contains all the details related to the HE configuration and packing. These details are automatically selected to ensure optimal performance given the user's requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_run_req = pyhelayers.HeRunRequirements()\n",
    "# Use the HEaaN context as the underlying FHE\n",
    "he_run_req.set_he_context_options([pyhelayers.HeaanContext()])\n",
    "# The encryption is at least as strong as 128-bit encryption.\n",
    "he_run_req.set_security_level(128)\n",
    "# Our numbers are theoretically stored with a precision of about 2^-40.\n",
    "he_run_req.set_fractional_part_precision(40)\n",
    "# The batch size for NN.\n",
    "he_run_req.optimize_for_batch_size(batch_size)\n",
    "# The model weights are kept in the plain\n",
    "he_run_req.set_model_encrypted(False)\n",
    "\n",
    "\n",
    "\n",
    "# Compile - run the optimizer\n",
    "profile = pyhelayers.HeModel.compile(nnp, he_run_req)\n",
    "\n",
    "profile_as_json = profile.to_string()\n",
    "# Profile supports I/O operations and can be stored on file.\n",
    "print(json.dumps(json.loads(profile_as_json), indent=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Initialize the context, and encrypt the NN\n",
    "Now we initialize the context object and encrypt the neural network using our profile object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=pyhelayers.HeModel.create_context(profile)\n",
    "nn = pyhelayers.NeuralNet(context)\n",
    "nn.encode(nnp, profile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Encrypt the input samples\n",
    "Here, we encrypt the samples we're going to be running an inference on. The data is encrypted by the iop object (input output processor), which contains model meta data only, and can process inputs and outputs of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iop=nn.create_io_processor()\n",
    "encrypted_samples = pyhelayers.EncryptedData(context)\n",
    "iop.encode_encrypt_inputs_for_predict(encrypted_samples, [plain_samples])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Run prediction over encrypted data, using the encrypted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encrypted_predictions = pyhelayers.EncryptedData(context)\n",
    "with utils.elapsed_timer('predict', batch_size) as timer:\n",
    "    nn.predict(encrypted_predictions, encrypted_samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 Decrypt the prediction result\n",
    "The final labels are computed as the argmax of the 10 predicted probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhe_model_predictions = iop.decrypt_decode_output(encrypted_predictions)\n",
    "fhe_predicted_labels = np.argmax(fhe_model_predictions, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9 Compare the predictions of the encrypted model with the predictions of the plain model\n",
    "The FHE model's predictions are shown to match those produced by the plain model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('labels predicted by the FHE model: ', fhe_predicted_labels)\n",
    "print('labels predicted by the plain model: ', plain_predicted_labels)\n",
    "np.testing.assert_array_equal(fhe_predicted_labels, plain_predicted_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moran Baruch, Nir Drucker, Gilad Ezov, Eyal Kushnir, Jenny Lerner, Omri Soceanu, Itamar Zimerman. \"Sensitive Tuning of Large Scale CNNs for E2E Secure Prediction using Homomorphic Encryption\" (2023)\n",
    "https://arxiv.org/abs/2304.14836"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "0e4a86c6de552a75de3f76546b88fdc07403a59a0ff9bc5c3fe3ef6120ab2c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
