{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ae97fe9",
   "metadata": {},
   "source": [
    "# Multi Party FHE\n",
    "Expected RAM usage: 7.3 GB\n",
    "Expected runtime: 2 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4351ebe6",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This example demonstrates a use of a multi-party FHE setting. In this setting, a set of parties wish to compute some function over their secret data while not revealing it to any of the other parties. Using a regular public-key setting will not be secure, since it requires the parties to trust the holder of the secret key (whether it is one of the parties or a \"trusted\" third party). In the multi-party FHE setting, none of the parties has a hold on the secret key. Instead, each party has its own secret key (therefore, it will also be called a \"key-owner\" later on). The public keys (which includes the encryption key and the evaluation keys) are generated in a initialization protocol (a.k.a InitProtocol) between the parties. To decrypt a ciphertext, each of the parties (key-owners) needs to give its consent and to take part in a decryption protocol (a.k.a. DecryptProtocol).\n",
    "\n",
    "In the following example we consider the case of 2 data owners - Alice and Bob - and a server. The security model requires that the server is not colluding with any of the data owners. The example demonstrates how an encrypted linear regression model can be trained with encrypted data of multiples data owners. After the training process is complete the model is decrypted and shared between the data owners. The model used in this example is a linear regression model.\n",
    "\n",
    "The input of each of the data owners (Alice and Bob) is a dataset of 100000\n",
    "samples and 1 feature contains fabricated data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad636124",
   "metadata": {},
   "source": [
    "## Step 1. Framework Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eaf08f",
   "metadata": {},
   "source": [
    "### 1.1. Start with some imports\n",
    "\n",
    "We import general pyhelayers classes (e.g., HeConfigRequirement; see details in the basic example notebooks) and multi-party specific classes:\n",
    "* MultiPartyConfig - Contains the configurations of the multi-party setting. It can be set directly from the python code or loaded from a json file (as we do in this example).\n",
    "* InitProtocol - Each protocol in the multi-party setting is represented as a protocol object. Each participant initializes its own protocol object and uses it to run the protocol and to get information about its status. The InitProtocol object is used to the run initialization protocol where the participants generate the public keys.\n",
    "* DecryptProtocol - The DecryptProtocol is used to the run decryption protocol where the participants decrypts a CTile / CTileTensor / EncryptedData object.\n",
    "* ProtocolMessage - During the run of the protocols, the protocol objects generate messages to send to other participants. These messages are represented as ProtocolMessage objects. These objects can be serialized and saved to memory or to a file. In addition, the ProtocolMessage object allows to get information about the message (e.g., whom is it destined for, on which round it should be received, etc.).\n",
    "* ProtocolMessageVector - When running a protocol, each participant collects at each round all the messages that are relevant to it. To feed these messages to the protocol object, the participants wrap their messages in a ProtocolMessageVector object.\n",
    "\n",
    "We also specify the path of two directories:\n",
    "* MULTI_PARTY_PATH - This directory contains the pre-prepared multi-party configurations files of Alice, Bob and the server.\n",
    "* COMMUNICATION_DIR_PATH - This is a temporary directory that will be used for saving and loading protocol messages and encrypted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ece131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import threading\n",
    "from pyhelayers import OpenFheCkksContext, MockupContext, HeConfigRequirement, RotationSetType\n",
    "from pyhelayers import PlainModelHyperParams, PlainModel, HeModel, HeRunRequirements, EncryptedData, LogisticRegressionPlain, LRActivation, LRDistribution, ModelIoEncoder\n",
    "from pyhelayers import MultiPartyConfig, InitProtocol, DecryptProtocol, ProtocolMessage, ProtocolMessageVector\n",
    "from utils import get_data_sets_dir, get_temp_output_data_dir, create_clean_dir\n",
    "\n",
    "MULTI_PARTY_PATH = os.path.join(get_data_sets_dir(), 'multi_party_fhe')\n",
    "COMMUNICATION_DIR_PATH = os.path.join(get_temp_output_data_dir(), 'multi_party_fhe')\n",
    "create_clean_dir(get_temp_output_data_dir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13c5be5",
   "metadata": {},
   "source": [
    "### 1.2. Set shared parameters\n",
    "\n",
    "Here we set the shared model hyper-parameters to be used by the parties. See other AI related notebooks for information about the different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596cd310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether to use mockup HE context in the example or to use a secure HE context.\n",
    "use_mockup = False\n",
    "\n",
    "req = HeConfigRequirement.insecure(\n",
    "    num_slots = 2 ** 15,\n",
    "    multiplication_depth = 18,\n",
    "    fractional_part_precision = 52,\n",
    "    integer_part_precision = 8) if use_mockup else HeConfigRequirement(\n",
    "        num_slots = 2 ** 15,\n",
    "        multiplication_depth = 18,\n",
    "        fractional_part_precision = 52,\n",
    "        integer_part_precision = 8)\n",
    "req.public_functions.rotate = RotationSetType.CUSTOM_ROTATIONS\n",
    "req.public_functions.set_rotation_steps([1, 16, 256, 4096])\n",
    "\n",
    "mean_x = 10.0\n",
    "std_x = 1.0\n",
    "std_x_noise_for_fabricated_data = 0.1\n",
    "phi0 = 50.0\n",
    "phi1 = -0.4\n",
    "num_samples_each_party = 100000\n",
    "\n",
    "hyper_params = PlainModelHyperParams()\n",
    "hyper_params.number_of_features = 1\n",
    "hyper_params.logistic_regression_activation = LRActivation.NONE\n",
    "hyper_params.linear_regression_distribution_x = LRDistribution.LR_NORMAL_DISTRIBUTION\n",
    "hyper_params.linear_regression_mean_x = mean_x\n",
    "hyper_params.linear_regression_std_x = std_x\n",
    "hyper_params.inverse_approximation_precision = 2\n",
    "hyper_params.trainable = True\n",
    "\n",
    "# This should equal the number of data owners. In our case there are two data owners (Alice and Bob).\n",
    "hyper_params.fit_hyper_params.number_of_iterations = 2\n",
    "\n",
    "# This should equal the maximal number of samples for each party. In our case there are at most num_samples_each_party samples for each party.\n",
    "hyper_params.fit_hyper_params.fit_batch_size = num_samples_each_party"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec63681",
   "metadata": {},
   "source": [
    "### 1.3. Define helper functions\n",
    "\n",
    "We define two helper functions to be used by the participants.\n",
    "\n",
    "* setup_participant gets the HeContext object, the name of the participant (a string) and the base HeConfigRequirement object. It loads into the HeConfigRequirement object the multi-party config of the current participant and initializes the HeContext object.\n",
    "* setup_he_model creates an empty linear regression model for the parties to train.\n",
    "* generate_encrypt_and_save_inputs generates fabricated input for Alice and Bob to encrypt and send to the server.\n",
    "* read_messages_and_execute_round gets the HeContext object and the Protocol object (either InitProtocol or DecryptProtocol in this example). It traverse all files in the communication directory, loads each of them into a ProtocolMessage object, and checks, using the is_input_message_valid_for_current_round method, if this message is relevant to them. All relevant message are collected into a ProtocolMessageVector object which is fed into the protocol object using the execute_next_round method. This method also generates the output message of the round, and returns a boolean value which equals True if the round was executed successfully. Finally, it saves all output message to the communication directory, using the get_metadata_as_string method to name each file (this method outputs the metadata of the ProtocolMessage into a human readable string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32274ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_participant(he, name, req):\n",
    "    # Read multi-party configuration file\n",
    "    f = open(os.path.join(MULTI_PARTY_PATH, 'multi_party_config_' + name + '.json'))\n",
    "    data = json.load(f)\n",
    "    mp_config = MultiPartyConfig()\n",
    "    mp_config.participant_id = data['participant_id']\n",
    "    mp_config.set_key_owners_ids(data['key_owners_ids'])\n",
    "    mp_config.initiator_id = data['initiator_id']\n",
    "    mp_config.aggregator_id = data['aggregator_id']\n",
    "    req.set_multi_party_config(mp_config)\n",
    "\n",
    "    # Initialize context\n",
    "    he.init(req)\n",
    "\n",
    "def setup_he_model(he, hyper_params):\n",
    "    # Unlike all other demos, in this demo we had to initialize an HeContext before initializing the HeModel.\n",
    "    # This is because the HeContext must be generated using a multi-party initialization protocol. This requires us to use a lower-level API than the simpler API shown in most other demos.\n",
    "    lrp = PlainModel.create(hyper_params)\n",
    "    he_run_req = HeRunRequirements()\n",
    "    \n",
    "    if use_mockup:\n",
    "        he_run_req.set_he_context_options([OpenFheCkksContext()])\n",
    "    else:\n",
    "        he_run_req.set_he_context_options([he])\n",
    "\n",
    "    he_run_req.set_explicit_he_config_requirement(he.get_he_config_requirement())\n",
    "    profile = HeModel.compile(lrp, he_run_req)\n",
    "    lr = lrp.get_empty_he_model(he)\n",
    "    lr.encode_encrypt(lrp, profile)\n",
    "    return lr\n",
    "\n",
    "def generate_encrypt_and_save_inputs(he, name, lr):\n",
    "    ioe = ModelIoEncoder(lr)\n",
    "    encrypted_inputs = EncryptedData(he)\n",
    "\n",
    "    # Create fabricated data\n",
    "    error = np.random.normal(0, 1, num_samples_each_party)\n",
    "    x = np.random.normal(mean_x, std_x + std_x_noise_for_fabricated_data, num_samples_each_party) \n",
    "    y = phi0 + phi1 * x + error\n",
    "\n",
    "    ioe.encode_encrypt(encrypted_inputs, [np.expand_dims(x, axis=1), np.expand_dims(y, axis=1)])\n",
    "    encrypted_inputs.save_to_file(os.path.join(COMMUNICATION_DIR_PATH, name + '_encrypted_data'))\n",
    "\n",
    "def read_messages_and_execute_round(he, protocol, exceptions):\n",
    "    try:\n",
    "        # Clear input messages queue\n",
    "        input_messages = ProtocolMessageVector()\n",
    "        output_messages = ProtocolMessageVector()\n",
    "\n",
    "        # Read messages from directory (here we load every message and check its metadata from the message object in memory. In other implementation we can keep the metadata in the file name and save the loading of unneeded messages).\n",
    "        for file in os.listdir(os.fsencode(COMMUNICATION_DIR_PATH)):\n",
    "            filename = os.fsdecode(file)\n",
    "\n",
    "            # Skip irrelevant messages\n",
    "            mp_config = he.get_he_config_requirement().get_multi_party_config()\n",
    "            if \"round_\" + str(protocol.get_current_round()) not in filename \\\n",
    "                or \"source_id_\" + str(mp_config.participant_id) in filename \\\n",
    "                or (\"dest_role_AGGREGATOR\" in filename and not mp_config.is_aggregator()) \\\n",
    "                or (\"dest_role_KEY-OWNER\" in filename and not mp_config.is_key_owner()):\n",
    "                continue\n",
    "\n",
    "            message = ProtocolMessage(he)\n",
    "            message.load_from_file(os.path.join(COMMUNICATION_DIR_PATH, filename))\n",
    "            if protocol.is_input_message_valid_for_current_round(message):\n",
    "                input_messages.append(message)\n",
    "\n",
    "        # Execute round\n",
    "        result = protocol.execute_next_round(output_messages, input_messages)\n",
    "        assert result is True\n",
    "\n",
    "        # Upload messages to directory\n",
    "        for i, message in enumerate(output_messages):\n",
    "            message.save_to_file(os.path.join(COMMUNICATION_DIR_PATH, message.get_metadata_as_string(True) + '_' + str(i)))\n",
    "    except Exception as e:\n",
    "        exceptions[mp_config.participant_id] = e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c83f95a",
   "metadata": {},
   "source": [
    "### 1.4. Participants setup\n",
    "\n",
    "The setup phase includes loading the multi-party configuration objects from files and initializing the HeContext objects of the participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e7590",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*** Starting multi-party FHE demo ***')\n",
    "\n",
    "# Alice setup\n",
    "he_alice = MockupContext() if use_mockup else OpenFheCkksContext()\n",
    "setup_participant(he_alice, 'alice', req)\n",
    "\n",
    "# Bob setup\n",
    "he_bob = MockupContext() if use_mockup else OpenFheCkksContext()\n",
    "setup_participant(he_bob, 'bob', req)\n",
    "\n",
    "# Server setup\n",
    "he_server = MockupContext() if use_mockup else OpenFheCkksContext()\n",
    "setup_participant(he_server, 'server', req)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa4b093",
   "metadata": {},
   "source": [
    "## Step 2. Initialization protocol\n",
    "\n",
    "In the initialization protocol the participants generate the public keys. We first initialize the protocol object for each participant and then run the protocol using the helper function (see information above). The method needs_another_round returns True if the protocol needs another round. In the example below with call it on Alice's protocol object, but in real world use each participant will use its own object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10d93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*** Initialization protocol ***')\n",
    "\n",
    "create_clean_dir(COMMUNICATION_DIR_PATH)\n",
    "\n",
    "# Alice side\n",
    "init_protocol_alice = InitProtocol(he_alice)\n",
    "\n",
    "# Bob side\n",
    "init_protocol_bob = InitProtocol(he_bob)\n",
    "\n",
    "# Server side\n",
    "init_protocol_server = InitProtocol(he_server)\n",
    "\n",
    "exceptions = {}\n",
    "while init_protocol_alice.needs_another_round():\n",
    "    \n",
    "    th_alice = threading.Thread(target=read_messages_and_execute_round, args=(he_alice, init_protocol_alice, exceptions))\n",
    "    th_bob = threading.Thread(target=read_messages_and_execute_round, args=(he_bob, init_protocol_bob, exceptions))\n",
    "    th_server = threading.Thread(target=read_messages_and_execute_round, args=(he_server, init_protocol_server, exceptions))\n",
    " \n",
    "    th_alice.start()\n",
    "    th_bob.start()\n",
    "    th_server.start()\n",
    "\n",
    "    th_alice.join()\n",
    "    th_bob.join()\n",
    "    th_server.join()\n",
    "\n",
    "    if len(exceptions) > 0:\n",
    "        raise Exception(exceptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bfe4c5",
   "metadata": {},
   "source": [
    "## Step 3. Homomorphic computation\n",
    "\n",
    "At this point all parties have the public keys, and they can encrypt and perform homomorphic computation. Alice and Bob will each initialize an empty HE model and use it to encrypt their inputs and send them to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f662697",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*** Encrypt inputs ***')\n",
    "\n",
    "create_clean_dir(COMMUNICATION_DIR_PATH)\n",
    "\n",
    "# Alice side\n",
    "lr_alice = setup_he_model(he_alice, hyper_params)\n",
    "generate_encrypt_and_save_inputs(he_alice, \"alice\", lr_alice)\n",
    "\n",
    "# Bob side\n",
    "lr_bob = setup_he_model(he_bob, hyper_params)\n",
    "generate_encrypt_and_save_inputs(he_bob, \"bob\", lr_bob)\n",
    "\n",
    "# The server initializes an empty HE model, loads Alice's and Bob's encrypted inputs and trains the model.\n",
    "\n",
    "print('*** Train encrypted model ***')\n",
    "\n",
    "# Server side\n",
    "ed0 = EncryptedData(he_server)\n",
    "ed1 = EncryptedData(he_server)\n",
    "ed0.load_from_file(os.path.join(COMMUNICATION_DIR_PATH, 'alice_encrypted_data'))\n",
    "ed1.load_from_file(os.path.join(COMMUNICATION_DIR_PATH, 'bob_encrypted_data'))\n",
    "\n",
    "# This merges the two EncryptedData elements into one element.\n",
    "ed0.add_encrypted_data(ed1)\n",
    "\n",
    "lr_server = setup_he_model(he_server, hyper_params)\n",
    "lr_server.fit(ed0)\n",
    "\n",
    "# The server extracts the encrypted internals of the trained model.\n",
    "encrypted_model_internals = lr_server.get_encrypted_internals()\n",
    "\n",
    "# Now, Alice and Bob wish to decrypt the model. Alice will be the\n",
    "# plaintext-aggregator (i.e., the one who gets the decrypted model first),\n",
    "# and she will share the result with Bob."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8778d42",
   "metadata": {},
   "source": [
    "## Step 4. Decrypt protocol\n",
    "\n",
    "There are two important roles in the decryption protocol:\n",
    "* Plaintext aggregator - this is the participant that will get the decrypted result. The plaintext aggregator in this example is Alice, so each participant uses the set_plaintext_aggregator_id method to set the plaintext aggregator ID to be Alice's ID (we assume that the IDs are public and known in advance by all participants). After the run of the protocol, Alice uses the get_output_vector_double method to get the decrypted data. When running the decryption protocol with input of type CTileTensor or EncryptedData, the plaintext aggregator should use the get_output_double_tensor method or the get_output_vector_double_tensor method respectively.\n",
    "* Ciphertext holder - this is the participant who loads the ciphertext to decrypt into the DecryptProtocol object. In this example it is the server which loads a CTile object. The decryption protocol can also run with input of type CTileTensor and EncryptedData.\n",
    "\n",
    "NOTE: in this example, the plaintext aggregator is a key-owner, i.e., it has one of the secret keys. Therefore, it is safe for all other participants to publish their messages in a shared communication directory. When the plaintext aggregator is not a key-owner, all participant MUST send their messages directly to it in a secure channel. Otherwise, the ciphertext could be decrypted by anyone who have access to the communication directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e439f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*** Decryption protocol ***')\n",
    "\n",
    "create_clean_dir(COMMUNICATION_DIR_PATH)\n",
    "\n",
    "# The IDs are known by each of the participants\n",
    "alice_id = he_alice.get_he_config_requirement().get_multi_party_config().participant_id\n",
    "\n",
    "# Alice side\n",
    "decrypt_protocol_alice = DecryptProtocol(he_alice)\n",
    "decrypt_protocol_alice.set_plaintext_aggregator_id(alice_id)\n",
    "\n",
    "# Bob side\n",
    "decrypt_protocol_bob = DecryptProtocol(he_bob)\n",
    "decrypt_protocol_bob.set_plaintext_aggregator_id(alice_id)\n",
    "\n",
    "# Server side\n",
    "decrypt_protocol_server = DecryptProtocol(he_server)\n",
    "decrypt_protocol_server.set_plaintext_aggregator_id(alice_id)\n",
    "\n",
    "# The server also needs to load the ciphertext\n",
    "decrypt_protocol_server.set_input(encrypted_model_internals)\n",
    "\n",
    "exceptions = {}\n",
    "while decrypt_protocol_alice.needs_another_round():\n",
    "    th_alice = threading.Thread(target=read_messages_and_execute_round, args=(he_alice, decrypt_protocol_alice, exceptions))\n",
    "    th_bob = threading.Thread(target=read_messages_and_execute_round, args=(he_bob, decrypt_protocol_bob, exceptions))\n",
    "    th_server = threading.Thread(target=read_messages_and_execute_round, args=(he_server, decrypt_protocol_server, exceptions))\n",
    " \n",
    "    th_alice.start()\n",
    "    th_bob.start()\n",
    "    th_server.start()\n",
    "\n",
    "    th_alice.join()\n",
    "    th_bob.join()\n",
    "    th_server.join()\n",
    "\n",
    "    if len(exceptions) > 0:\n",
    "        raise Exception(exceptions)\n",
    "        break\n",
    "\n",
    "# Alice gets the output\n",
    "decoded_model_internals = decrypt_protocol_alice.get_output_vector_double_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alice uses the decoded model internals to build a plain model.\n",
    "trained_plain_model = lr_alice.get_plain_model_from_decoded_internals(decoded_model_internals)\n",
    "trained_plain_model.__class__ = LogisticRegressionPlain\n",
    "\n",
    "# Check result\n",
    "trained_weights = trained_plain_model.get_weights()[0]\n",
    "trained_bias = trained_plain_model.get_bias()[0]\n",
    "np.testing.assert_almost_equal(phi0, trained_weights, 1)\n",
    "np.testing.assert_almost_equal(phi1, trained_bias, 1)\n",
    "print('*** Checking results... OK ***')\n",
    "\n",
    "shutil.rmtree(COMMUNICATION_DIR_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
