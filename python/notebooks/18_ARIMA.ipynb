{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA training and prediction on encrypted data\n",
    "Expected RAM usage: 20 GB.\n",
    "Expected runtime: 30-60 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This example demonstrates FHE training of an ARIMA(1,1,1) model on encrypted time series values. The train model is also used to predict the next value of the time series. The FHE prediction is compared with the plain ARIMA(1,1,1) prediction and the prediction results are shown to be close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that HEaaN backend is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pyhelayers\n",
    "if not hasattr(pyhelayers, \"HeaanContext\"):\n",
    "    print(\"This demo requires HEaaN backend which is not yet available for this platform\")\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Client side - initialize ARIMA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Generate time series values of an ARIMA(1,1,1) model, in the plain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import utils\n",
    "\n",
    "mu = 50\n",
    "phi1 = 0.6\n",
    "phi2 = -0.4\n",
    "M = mu/(1-phi1)\n",
    "N = 2 ** 15\n",
    "\n",
    "errors = np.random.normal(0, 1, N)\n",
    "X_train = [M]\n",
    "for t in range(1,N):\n",
    "    X_train.append(mu + phi1*X_train[t-1] + phi2*errors[t-1] + errors[t])\n",
    "X_train = np.array(X_train).reshape([len(X_train), 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load the hyperparameters of the ARIMA(1,1,1) model\n",
    "These hyperparameters configure the FHE training and prediction algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params_file = os.path.join(utils.get_data_sets_dir(), 'arima', 'model.json')\n",
    "hyper_params = pyhelayers.PlainModelHyperParams()\n",
    "hyper_params.load(hyper_params_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Define HE run requirements\n",
    "These requirements specify how the HE encryption should be configured. Here, we require the HE encryption to be done with HEaaN encryption scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_run_req = pyhelayers.HeRunRequirements()\n",
    "he_run_req.set_he_context_options([pyhelayers.HeaanContext()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Initialize an HE Arima model.\n",
    "We initialized the HE Arima model with the above created HE run requirements. Calling `encode_encrypt` below activates an internal optimization process which finds the best HE-related configuration satisfying the given requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_arima = pyhelayers.Arima()\n",
    "he_arima.encode_encrypt(files=[], he_run_req=he_run_req, hyper_params=hyper_params)\n",
    "he_context = he_arima.get_created_he_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Get a `ModelIoEncoder` from the HE model.\n",
    "The ModelIoEncoder objects will be used to encrypt and decrypt the input and output of the training and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_io_encoder = pyhelayers.ModelIoEncoder(he_arima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Encrypt the training input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc = pyhelayers.EncryptedData(he_context)\n",
    "model_io_encoder.encode_encrypt(X_train_enc, [X_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Save the initialized HE Arima model and encrypted input to a buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_arima_buf = he_arima.save_to_buffer()\n",
    "X_train_enc_buf = X_train_enc.save_to_buffer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Server side - train the He Arima model over encrypted data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load the initialized HE Arima model and encrypted input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_he_arima = pyhelayers.load_he_model(he_context, he_arima_buf)\n",
    "server_x_train_enc = pyhelayers.load_encrypted_data(he_context, X_train_enc_buf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Train the Arima model over encrypted data\n",
    "This step results with a trained Arima model whose weights are encrypted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_he_arima.fit(server_x_train_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Save the trained Arima model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_arima_buf = server_he_arima.save_to_buffer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Client side - decrypt training results and encrypt prediction input.\n",
    "We will decrypt the above trained model and encrypt the time series we want to predict its next value. We demonstrate a use case in which the prediction input is owned by a separate entity. This separate entity will encrypt its input and send it to the server side for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Load and decrypt the trained Arima model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_arima = pyhelayers.load_he_model(he_context, fit_arima_buf)\n",
    "plain_arima = he_arima.decrypt_decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Build a new HE run requirements.\n",
    "The HE run requirements specify how the HE encryption should be configured. We build new requirements that are tailored for prediction. This time, we choose to not encrypt the model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_run_req2 = pyhelayers.HeRunRequirements()\n",
    "he_run_req2.set_he_context_options([pyhelayers.HeaanContext()])\n",
    "he_run_req2.set_model_encrypted(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Compile the plain model and HE run requirements into HE profile\n",
    "This HE profile holds encryption-specific parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = pyhelayers.HeModel.compile(plain_arima, he_run_req2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Initialize an HE Arima model.\n",
    "We initialized the HE Arima model using the plain Arima model and the HE profile computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_context = pyhelayers.HeModel.create_context(profile)\n",
    "he_arima = plain_arima.get_empty_he_model(he_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Encode the HE Arima model\n",
    "We encode the HE Arima model using the weights from the plain Arima model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_arima.encode(plain_arima, profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Create and save an `ModelIoEncoder` object\n",
    "This ModelIoEncoder can be sent to a separate entity that owns the prediction input. The separate entity then uses this IoProcessor to encrypt its data and send it to the server for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_io_encoder = pyhelayers.ModelIoEncoder(he_arima)\n",
    "model_io_encoder_buf = model_io_encoder.save_to_buffer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Encrypt the prediction input\n",
    "We load the ModelIoEncoder object saved above and use it to encrypt the prediction input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input = X_train[-hyper_params.num_values_used_for_prediction:]\n",
    "model_io_encoder = pyhelayers.load_io_encoder(he_context, model_io_encoder_buf)\n",
    "predict_input_enc = pyhelayers.EncryptedData(he_context)\n",
    "model_io_encoder.encode_encrypt(predict_input_enc, [predict_input])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Save the encoded Arima model and input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_arima_buf = he_arima.save_to_buffer()\n",
    "predict_input_enc_buf = predict_input_enc.save_to_buffer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Server side - predict over encrypted data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Load the encoded HE Arima model and input\n",
    "This model includes plaintext weights, and it will be used to run prediction over encrypted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_arima = pyhelayers.load_he_model(he_context, he_arima_buf)\n",
    "predict_input_enc = pyhelayers.load_encrypted_data(he_context, predict_input_enc_buf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Run FHE prediction.\n",
    "This step returns an encrypted prediction result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Homomorphically predicting the next value in the time series . . .')\n",
    "res_enc = pyhelayers.EncryptedData(he_context)\n",
    "he_arima.predict(res_enc, predict_input_enc)\n",
    "res_enc_buf = res_enc.save_to_buffer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Client side - decrypt and assess result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Decrypt the prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Decrypting the prediction result . . .')\n",
    "res_enc = pyhelayers.load_encrypted_data(he_context, res_enc_buf)\n",
    "res = model_io_encoder.decrypt_decode_output(res_enc)\n",
    "fhe_prediction = res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Compute the expected prediction, in the plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_prediction = mu + phi1 * X_train[-1] + phi2 * errors[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Compare the FHE prediction with the expected plain prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('FHE ARIMA(1,1,1) prediction = ', fhe_prediction)\n",
    "print('plain ARIMA(1,1,1) prediction = ', plain_prediction)\n",
    "absolute_diff = math.fabs(fhe_prediction - plain_prediction)\n",
    "relative_diff = absolute_diff / math.fabs(plain_prediction)\n",
    "print('absolute diff  = ', absolute_diff)\n",
    "print('relative_diff = ', relative_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RAM usage:\", utils.get_used_ram(), \"MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f497b8fb6983b2b7e8d6051f4315e544585546557ee2f98a631c292ad437c819"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
