{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means Inference Using FHE\n",
    "\n",
    "expected RAM usage: less than 1 GB  \n",
    "expected runtime: less than 30 seconds.\n",
    "\n",
    "## Introduction\n",
    "K-means clustering is one of the simplest and most popular unsupervised approaches when you have unlabeled data. Typically, unsupervised algorithms make inferences from datasets using only input vectors without referring to known, or labelled, outcomes. The K-means inference performed is used to compute the nearest centroid for a set of input vectors. Now, we are able to perform K-means clustering in a fully encrypted fashion.\n",
    "\n",
    "## Use case\n",
    "One potential FHE use case using K-means is secure anomaly detection and can be applied to supply chain use cases in a multitude of industries ranging from automotive to energy to defense. Customer mandates for improved services are the catalyst behind the speed required for all processes. Further complicating the issue is the growing complexity of global supply chains, which has greatly increased transaction flows and the volume and variety of data. These drivers have in turn increased the need for more efficient, timely and automated processing to manage the volume and contain the costs. Rising costs put pressure on logistics proviers to ensure accuracy and minimize the effort to track, analyze and report at all levels. Knowing the true cost-to-serve for supply chain leaders is the basis for many supplier sourcing decisions. \n",
    "\n",
    "With FHE, third-party logistics (3PL) providers can securely detect anomalies in a shipment cost, volume, weight, etc. in seconds and provide visibility for quick analysis while preserving the privacy of the shipment contents. For example, generally, you would expect if the weight or volume of a shipment is high, then the associated cost would also be high. But, if the package is extremely light and has a very high cost, it could be potentially anomalous and might need to be monitored in order to keep costs contained and improve service.\n",
    "\n",
    "We want to use FHE here because we are tracking metrics that may contain sensitive information like the price that companies are paying to the vendors, the source and destination of the shipment, or the current shipment details like volume and weight. The whole notion is based on the fact that the current shipment information is sensitive and historical information is not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Client side preparations\n",
    "### 1.1. Imports and some setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "import utils\n",
    "\n",
    "utils.verify_memory()\n",
    "\n",
    "np.set_printoptions(threshold=6,floatmode='maxprec',precision=3)\n",
    "\n",
    "import pyhelayers\n",
    "print(\"misc. init ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Define the features (the number of features and centroids)\n",
    "\n",
    "Each centroid represents a cluster. Data samples around that centroid will be labelled as the centroid. These are standard K-means parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims=4\n",
    "numCentroids=6\n",
    "centroids=np.zeros([0,dims])\n",
    "for i in range(numCentroids):\n",
    "    centroids=np.concatenate((centroids,np.random.randn(1,dims)*0.1+i))\n",
    "print(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Write the centorids coordinates to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('data', 'kmeans')\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# write CSV file\n",
    "f = open(os.path.join(data_dir,'model.csv'),\"w\")\n",
    "for x in range(numCentroids):\n",
    "    for y in range(dims):\n",
    "        if (y>0):\n",
    "            f.write(\",\")\n",
    "        f.write(str(centroids[x,y]))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "print(\"wrote csv file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Load and encrypt the model\n",
    "\n",
    "We now load and ecnrypt the model using helayers. The encryption function also runs internally an Optimizer that finds the best parameters for this model. We can provide various additional parameters as an input. In this demo:\n",
    "* We choose to optimize for the DefaultContext (SEAL)\n",
    "* We choose the batch size, how many samples would you provide each time for the inference model to do the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_run_req = pyhelayers.HeRunRequirements()\n",
    "he_run_req.set_he_context_options([pyhelayers.DefaultContext()])\n",
    "he_run_req.optimize_for_batch_size(8192)\n",
    "\n",
    "model_file = [os.path.join(data_dir,\"model.csv\")]\n",
    "\n",
    "client_kmeans = pyhelayers.KMeans()\n",
    "client_kmeans.encode_encrypt(model_file, he_run_req)\n",
    "client_context = client_kmeans.get_created_he_context()\n",
    "batch_size = client_kmeans.get_profile().get_optimal_batch_size()\n",
    "\n",
    "print(\"loaded and encrypted a KMeans model\")\n",
    "print(\"Batch size: \",batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Provide labels to each of the data samples according to the proximity of a centroid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=batch_size\n",
    "\n",
    "labels=np.random.randint(0,numCentroids,size=(test_size))\n",
    "\n",
    "test_data=np.zeros([0,dims])\n",
    "for i in range(test_size):\n",
    "    test_data=np.concatenate((test_data,np.random.randn(1,dims)*0.1+labels[i]))\n",
    "    \n",
    "print(test_data)\n",
    "print('labels',labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Encrypt the data samples\n",
    "\n",
    "To encrypt the data we first create a model io encoder.\n",
    "The model io encoder object is a lightweight object that knows the model's metadata and can be used to encrypt data for it, and later decrypt the output it sends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_io_encoder = pyhelayers.ModelIoEncoder(client_kmeans)\n",
    "client_samples = pyhelayers.EncryptedData(client_context)\n",
    "model_io_encoder.encode_encrypt(client_samples, [test_data])\n",
    "print('Batch encrypted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. Save and send\n",
    "We save the encrypted model, the context, and the samples in preparation for sending them to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_buffer = client_kmeans.save_to_buffer()\n",
    "samples_buffer = client_samples.save_to_buffer()\n",
    "context_buffer = client_context.save_to_buffer() # with no secret key\n",
    "print('Context, model, and samples saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Server side\n",
    "### 2.1. Load data\n",
    "We first load all the data sent from the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_context = pyhelayers.load_he_context(context_buffer)\n",
    "server_kmeans = pyhelayers.load_he_model(server_context,kmeans_buffer)\n",
    "server_samples = pyhelayers.load_encrypted_data(server_context,samples_buffer)\n",
    "print('server ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Run prediction\n",
    "\n",
    "With the inputs and centroids both encrypted, we find the distance between each input and each centroid.\n",
    "\n",
    "The results are saved to a buffer and sent back to the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.start_timer()\n",
    "\n",
    "server_predictions = pyhelayers.EncryptedData(server_context)\n",
    "server_kmeans.predict(server_predictions, server_samples)\n",
    "\n",
    "duration=utils.end_timer('predict')\n",
    "utils.report_duration('predict per sample',duration/test_size)\n",
    "\n",
    "predictions_buffer = server_predictions.save_to_buffer()\n",
    "print('predictions saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Assess results on the client side\n",
    "\n",
    "We first load the data and decrypt it, again using the model io encoder.\n",
    "\n",
    "Then we compare it with the ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_predictions = pyhelayers.load_encrypted_data(client_context,predictions_buffer)\n",
    "print('predictions loaded')\n",
    "\n",
    "# Decrypting results\n",
    "plain_predictions = model_io_encoder.decrypt_decode_output(client_predictions)\n",
    "\n",
    "print('HE predictions:',plain_predictions)\n",
    "print('True labels:',labels)\n",
    "allOk=(plain_predictions==labels).all()\n",
    "if (allOk):\n",
    "    print('All predictions match')\n",
    "else:\n",
    "    raise Exception(\"mismatching labels. Demo failed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
