{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means Inference Using FHE\n",
    "\n",
    "expected RAM usage: less than 1 GB  \n",
    "expected runtime: less than 30 seconds.\n",
    "\n",
    "## Introduction\n",
    "K-means clustering is one of the simplest and most popular unsupervised approaches when you have unlabeled data. Typically, unsupervised algorithms make inferences from datasets using only input vectors without referring to known, or labelled, outcomes. The K-means inference performed is used to compute the nearest centroid for a set of input vectors. Now, we are able to perform K-means clustering in a fully encrypted fashion.\n",
    "\n",
    "## Use case\n",
    "One potential FHE use case using K-means is secure anomaly detection and can be applied to supply chain use cases in a multitude of industries ranging from automotive to energy to defense. Customer mandates for improved services are the catalyst behind the speed required for all processes. Further complicating the issue is the growing complexity of global supply chains, which has greatly increased transaction flows and the volume and variety of data. These drivers have in turn increased the need for more efficient, timely and automated processing to manage the volume and contain the costs. Rising costs put pressure on logistics proviers to ensure accuracy and minimize the effort to track, analyze and report at all levels. Knowing the true cost-to-serve for supply chain leaders is the basis for many supplier sourcing decisions. \n",
    "\n",
    "With FHE, third-party logistics (3PL) providers can securely detect anomalies in a shipment cost, volume, weight, etc. in seconds and provide visibility for quick analysis while preserving the privacy of the shipment contents. For example, generally, you would expect if the weight or volume of a shipment is high, then the associated cost would also be high. But, if the package is extremely light and has a very high cost, it could be potentially anomalous and might need to be monitored in order to keep costs contained and improve service.\n",
    "\n",
    "We want to use FHE here because we are tracking metrics that may contain sensitive information like the price that companies are paying to the vendors, the source and destination of the shipment, or the current shipment details like volume and weight. The whole notion is based on the fact that the current shipment information is sensitive and historical information is not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Client side preparations\n",
    "### 1.1. Imports and some setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "import utils\n",
    "\n",
    "utils.verify_memory()\n",
    "\n",
    "np.set_printoptions(threshold=6,floatmode='maxprec',precision=3)\n",
    "\n",
    "import pyhelayers\n",
    "print(\"misc. init ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Define the features (the number of features and centroids)\n",
    "\n",
    "Each centroid represents a cluster. Data samples around that centroid will be labelled as the centroid. These are standard K-means parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims=4\n",
    "numCentroids=6\n",
    "centroids=np.zeros([0,dims])\n",
    "for i in range(numCentroids):\n",
    "    centroids=np.concatenate((centroids,np.random.randn(1,dims)*0.1+i))\n",
    "print(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Write the centorids coordinates to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('data', 'kmeans')\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# write CSV file\n",
    "f = open(os.path.join(data_dir,'model.csv'),\"w\")\n",
    "for x in range(numCentroids):\n",
    "    for y in range(dims):\n",
    "        if (y>0):\n",
    "            f.write(\",\")\n",
    "        f.write(str(centroids[x,y]))\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "print(\"wrote csv file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Load the model\n",
    "\n",
    "We now load the model into helayers. It's still in plaintext (not yet encrypted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = pyhelayers.PlainModelHyperParams()\n",
    "plain = pyhelayers.KMeansPlain()\n",
    "plain.init_from_files(hyper_params, [os.path.join(data_dir,\"model.csv\")])\n",
    "print(\"loaded plain model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Compile the plain model\n",
    "\n",
    "Now we take the plain model and run a process called compilation. This runs internally an Optimizer that finds the best parameters for this model. Not only does the Optimizer find the best parameters for you, but it also gives you estimations on the time it would take to predict using a single core, the precision, the memory, the time it would take to encrypt/decrypt, etc. \n",
    "\n",
    "The input to the compilation process are some preferences that we have. In this demo:\n",
    "* We choose to optimize for the DefaultContext (SEAL)\n",
    "* We choose the batch size, how many samples would you provide each time for the inference model to do the classification\n",
    "\n",
    "This step doesn't yet encrypt the model, but prepares a 'profile' object that we can later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_run_req = pyhelayers.HeRunRequirements()\n",
    "he_run_req.set_he_context_options([pyhelayers.DefaultContext()])\n",
    "he_run_req.optimize_for_batch_size(8192)\n",
    "\n",
    "profile = pyhelayers.HeModel.compile(plain, he_run_req)\n",
    "\n",
    "batch_size = profile.get_optimal_batch_size()\n",
    "print(profile.to_string())\n",
    "\n",
    "print(\"He profile ready\")\n",
    "print(\"Batch size: \",batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Initialize the context\n",
    "\n",
    "Here we initialize the FHE library based on the paramaters chosen for us in the profile object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_context = pyhelayers.HeModel.create_context(profile)\n",
    "print('Crypto-library ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. Encrypt the resulting K-means centroids in preparation for inferencing to find the nearest cluster for a sample\n",
    "\n",
    "Now we can encrypt our model, again using parameters chosen for us in the profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client_kmeans = pyhelayers.KMeans(client_context)\n",
    "print('\\rencrypting . . .\\r',flush=True)\n",
    "client_kmeans.encode_encrypt(plain, profile)\n",
    "print('encrypted KMeans ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8. Provide labels to each of the data samples according to the proximity of a centroid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=batch_size\n",
    "\n",
    "labels=np.random.randint(0,numCentroids,size=(test_size))\n",
    "\n",
    "test_data=np.zeros([0,dims])\n",
    "for i in range(test_size):\n",
    "    test_data=np.concatenate((test_data,np.random.randn(1,dims)*0.1+labels[i]))\n",
    "    \n",
    "print(test_data)\n",
    "print('labels',labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9. Encrypt the data samples\n",
    "\n",
    "To encrypt the data we first create an io processor (iop for short).\n",
    "The iop object is a lightweight object that knows the model's metadata and can be used to encrypt data for it, and later decrypt the output it sends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iop=client_kmeans.create_io_processor()\n",
    "client_samples = pyhelayers.EncryptedData(client_context)\n",
    "iop.encode_encrypt_inputs_for_predict(client_samples, [test_data])\n",
    "print('Batch encrypted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.10. Save and send\n",
    "We save the encrypted model, the context, and the samples in preparation for sending them to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_buffer = client_kmeans.save_to_buffer()\n",
    "samples_buffer = client_samples.save_to_buffer()\n",
    "context_buffer = client_context.save_to_buffer() # with no secret key\n",
    "print('Context, model, and samples saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Server side\n",
    "### 2.1. Load data\n",
    "We first load all the data sent from the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_context = pyhelayers.load_he_context(context_buffer)\n",
    "server_kmeans = pyhelayers.load_he_model(server_context,kmeans_buffer)\n",
    "server_samples = pyhelayers.load_encrypted_data(server_context,samples_buffer)\n",
    "print('server ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Run prediction\n",
    "\n",
    "With the inputs and centroids both encrypted, we find the distance between each input and each centroid.\n",
    "\n",
    "The results are saved to a buffer and sent back to the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.start_timer()\n",
    "\n",
    "server_predictions = pyhelayers.EncryptedData(server_context)\n",
    "server_kmeans.predict(server_predictions, server_samples)\n",
    "\n",
    "duration=utils.end_timer('predict')\n",
    "utils.report_duration('predict per sample',duration/test_size)\n",
    "\n",
    "predictions_buffer = server_predictions.save_to_buffer()\n",
    "print('predictions saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Assess results on the client side\n",
    "\n",
    "We first load the data and decrypt it, again using the 'iop'.\n",
    "\n",
    "Then we compare it with the ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_predictions = pyhelayers.load_encrypted_data(client_context,predictions_buffer)\n",
    "print('predictions loaded')\n",
    "\n",
    "# Decrypting results\n",
    "plain_predictions = iop.decrypt_decode_output(client_predictions)\n",
    "\n",
    "print('HE predictions:',plain_predictions)\n",
    "print('True labels:',labels)\n",
    "allOk=(plain_predictions==labels).all()\n",
    "if (allOk):\n",
    "    print('All predictions match')\n",
    "else:\n",
    "    raise Exception(\"mismatching labels. Demo failed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
